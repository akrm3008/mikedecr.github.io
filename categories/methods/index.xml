<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Methods on Michael DeCrescenzo</title>
    <link>/categories/methods/</link>
    <description>Recent content in Methods on Michael DeCrescenzo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/methods/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Causal Mediation, Bayesianly (with Stan)</title>
      <link>/2019/2019-06-19_bayesian-causal-mediation/</link>
      <pubDate>Wed, 19 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/2019-06-19_bayesian-causal-mediation/</guid>
      <description>Motivation for this post Over this summer, I have been organizing a reading group on causal inference for students in my department. As someone who sees data analysis problems primarily through Bayesian goggles, I have been doing extra work in my head to make sense of ‚ÄúBayesian causal inference.‚Äù I‚Äôm hoping to write some articles about this for political scientists, but the dissertation (rightly) has more of my attention lately.</description>
    </item>
    
    <item>
      <title>Plain Text Research: None of us know what we&#39;re doing</title>
      <link>/2019/2019-05-23_git-workflow/</link>
      <pubDate>Thu, 23 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/2019-05-23_git-workflow/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What if &#34;validity trade-offs&#34; are actually just priors</title>
      <link>/2019/2019-05-31_validity-trade-offs/</link>
      <pubDate>Thu, 23 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/2019-05-31_validity-trade-offs/</guid>
      <description>Outline  The conventional wisdom The Samii view, there is no trade-off My view: there is a trade-off, but we haven‚Äôt modeled it well  GGK vibes: we learn because there are priors Partial pooling analogy: the value of hyperpriors matters less than the structure This is what so-called ‚Äúexternally valid‚Äù larger scale research is. It‚Äôs not identified, so it‚Äôs not ‚Äúgeneral‚Äù but what it‚Äôs doing is providing a structure for organizing information Large scale research is an informal prior for pooling information from lower-level studies.</description>
    </item>
    
    <item>
      <title>Operationalizations Make Random Variables</title>
      <link>/2019/2019-05-07_operationalizations/</link>
      <pubDate>Tue, 07 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/2019-05-07_operationalizations/</guid>
      <description>Paul Musgrave tweeted recently that operationalizations aren‚Äôt definitions. In his own words:  Operationalizations aren‚Äôt definitions ‚Äî Paul Musgrave (@profmusgrave) May 6, 2019    When we do social science, our theories involve ‚Äúforces at work‚Äù in the world. Definitions of those forces are conceptual discussions, while operationalizations are measurement strategies for turning the concept into a data point.
I saw this tweet and, after agreeing with its argument, wanted to take it further.</description>
    </item>
    
    <item>
      <title>The Model is Itself a Hierarchical Variable</title>
      <link>/2019/2019-05-07_effect-distributions/</link>
      <pubDate>Tue, 07 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/2019-05-07_effect-distributions/</guid>
      <description>Tweets  I should do more than vague-tweet abt this. üî∏ Treatment fx are unknown! I think techniques that tell us about the distribution of plausible fx are improvements over ‚Äúrobustness tests‚Äù if the latter focus on the robustness of the num. of stars vs substantive inferences about fx üî∏ Engaging directly w/ the parameter val as the actual qty of interest, not its sign. Maybe it‚Äôs just me but I can‚Äôt grok a ‚Äúpurely directional‚Äù hypotheses.</description>
    </item>
    
    <item>
      <title>Bayesian Estimates of Wait Times at the Polls</title>
      <link>/2019/2019-03-21_bayesian-wait-times/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/2019-03-21_bayesian-wait-times/</guid>
      <description>Charles Stewart tweeted some figures on the estimated average wait time to vote in 2018 (compared to 2014 and 2016). These data come from the CCES and the SPAE. Interestingly, neither of these surveys are able to get a direct measure of wait time. This makes sense; a voter will not remember if they were in line for 6 minutes versus 7. Instead, the surveys ask for a binned response.</description>
    </item>
    
    <item>
      <title>Experimentalists Agree! When Flat Priors Lead to Worse Learning</title>
      <link>/2019/2019-02-23_gerber-green-kaplan/</link>
      <pubDate>Sat, 23 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/2019-02-23_gerber-green-kaplan/</guid>
      <description>I‚Äôve been reading about Bayesian causal inference for a paper I‚Äôm hoping to write, and this has led me to dig into the work by Gerber, Green, and Kaplan about the ‚ÄúIllusion of Learning from Observational Research.‚Äù In it, they put forth a model to describe how much you ‚Äúupdate‚Äù your information about causal effects from experimental vs observational research.
The intuition of the model is to suppose that we want to learn about some causal effect \(M\).</description>
    </item>
    
    <item>
      <title>Using the Tidyverse with Voter Registration Linkage Data</title>
      <link>/2018/2018-11-29-hava-xl/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/2018-11-29-hava-xl/</guid>
      <description>a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.</description>
    </item>
    
    <item>
      <title>A Visualization of Partial Effects in Multiple Regression</title>
      <link>/2018/2018-10-19-partialling-out/</link>
      <pubDate>Fri, 19 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/2018-10-19-partialling-out/</guid>
      <description>a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.</description>
    </item>
    
    <item>
      <title>Packages &amp; Reproducibility: Install what you need, attach what you want</title>
      <link>/2018/2018-05-26-reproducible-packages/</link>
      <pubDate>Wed, 30 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/2018-05-26-reproducible-packages/</guid>
      <description>a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.</description>
    </item>
    
  </channel>
</rss>
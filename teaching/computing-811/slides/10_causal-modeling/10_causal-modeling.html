<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Causal Inference 1: Design</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.1/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: middle, center







.pull-left[
# **PS 811: Statistical Computing**

&lt;br&gt;
Michael DeCrescenzo
&lt;br&gt;
University of Wisconsin–Madison

]

.pull-right[
&lt;img src="10_causal-modeling_files/figure-html/title-graphic-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]

## Causal and Predictive Modeling 1/2: &lt;br&gt; Causal Inference

April 24, 2020

---

class: middle

.pull-left[

## Objectives

1. Mathematical models of causal inference

2. Pre-treatment and post-treatment confounding

3. Example: Regression Discontinuity and Bootstrapping
]


.pull-right[

## Code demo

1. `08_rdd-bootstrap.R` from Canvas

2. `hall_house-primaries.dta` from Canvas (save in `data` folder)

]


---

# Causal Inference

"Correlation is not causaion"

Attempts at understanding _how to achieve "causality"_ have been informal or semi-formal


--

### Objectives

1. What is the **causal quantity** that we want to know?

2. What are the **assumptions required** to learn about it?

3. What **research designs/estimation methods** satisfy those assumptions?

---

.pull-left[
## "Potential Outcomes"

a.k.a. the "Rubin" causal model

`\(Y_{i}\)` is a function of treatment `\(Z_{i}\)`

`\(Y_{i}(z)\)` is "potential outcome" under treatment `\(Z = z\)`

Binary case, `\(Y_{i}(1)\)` and `\(Y_{i}(0)\)`.

Causal effect: `\(Y_{i}(1) - Y_{i}(0)\)`

**Fundamental problem of causal inference:** never observe both POs for `\(i\)`

Causal identification if `\(Y_{i}(z) \perp \!\!\! \perp Z_{i}\)`

]

--

.pull-right[

## "DAGs/Do-Calculus"

Judea Pearl (also Robins, Hernán...)

Observing: `\(p(Y \mid Z = z)\)`

Intervening: `\(p(Y \mid \mathit{do}(Z = z))\)`

Causal effect: `\(p(Y \mid \mathit{do}(1)) \neq p(Y \mid \mathit{do}(0))\)`

Causal identification if `\(p(Y \mid Z) = p(Y \mid \mathit{do}(Z))\)`

Problem: conditioning on the right stuff. (Directed Acyclic Graphs &amp; _do_-calculus)

]


---

## Causal Models

Two ways of writing the same basic ideas: `\(Z\)` has a causal effect if at least one unit's outcome would be different by changing `\(Z\)`

**Fundamental problem of causal inference**: We can't observe whether one unit changes.

Can compare **average outcomes**, but can't make a causal claim **without assumptions**

- Potential outcomes: Treatment assignment is _independent of potential outcomes_ (optional: after conditioning on confounders)

- Do-calculus: The "observed distribution" is equal to the "interventional distribution" (optional: after conditioning on confounders)


---

## What is Confounding





.pull-left[

&lt;img src="10_causal-modeling_files/figure-html/plot-confound-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]


.pull-right[
`\(X\)` confounds the effect of `\(Z\)` on `\(Y\)` (creates a "back door path" from `\(Z\)` to `\(Y\)`)

To identify `\(Z\)`'s effect, must adjust for `\(X\)` ("block" the back-door path)

Potential outcomes `\(Y(z) \perp \!\!\! \perp Z \mid X\)`

or `\(p(Y \mid do(Z)) = p(Y \mid Z, X)p(X)\)`

DAG for **nonparametric identification**; does not tell us that linear regression works

]


---

### Collider (a.k.a. "Post-Treatment") Bias




.pull-left[

&lt;img src="10_causal-modeling_files/figure-html/plot-collider-1.png" width="90%" style="display: block; margin: auto;" /&gt;

"Bad control" **creates new paths**

- Conditioning on `\(C\)` creates path `\(Z \rightarrow X \rightarrow Y\)`

]

--
.pull-right[

Creates relationships that **aren't there**

- Assume attractiveness ( `\(Z\)` ) and personality ( `\(X\)` ) are unrelated
- Both positively affect being in a relationship ( `\(C\)` )
- Among singles ( controlling for `\(C\)` ), attractiveness and personality negatively related

Lots of things affect `\(Y\)`. **Doesn't mean you should control for them.**

]






---

## Why experiments work




.pull-left[

&lt;img src="10_causal-modeling_files/figure-html/plot-exp-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]


.pull-right[

Assignment to treatment `\(Z\)` is random.

Even if other factors `\(X\)` affect `\(Y\)`, they do not confound the treatment effect

**No back door path** from `\(Z\)` to `\(Y\)` that goes through `\(X\)`

]




---

class: middle

.pull-left[
### Causal Assumptions

- Begin with a model of potential outcomes

- What assumptions enable us to identify _causal variation_ in treatment?

- Assumptions usually relate to conditional independences among variables

]


.pull-right[
### Statistical Assumptions

- What **statistical** assumptions are we layering on top of the **causal** assumptions?

- What research designs let us make **fewer assumptions** about functional forms, relevant covariates, etc.?

- Can we **design away** some of these more difficult assumptions?

]


---


### Regression Discontinuity

.pull-left[
Units are treated if value of a "running variable" `\(X\)` falls on one side of a **threshold** (cutoff)

- I win an election if vote margin &gt; 0
- I'm accepted into program if test score high enough

RD design estimates the LOCAL AVERAGE TREATMENT EFFECT **at the cutoff**

- Key assumption: regression function `\(E[Y \mid X]\)` is **continuous at the cutoff**

]


.pull-right[

&lt;img src="10_causal-modeling_files/figure-html/rdd-plot-1.png" width="100%" style="display: block; margin: auto;" /&gt;

Linear RDD:
`\begin{align}
  y_i &amp;= \alpha + \delta \text{Treat}_i + \beta_1 X_{i} + \beta_2 (X_{i} \times \text{Treat}_{i})
\end{align}`

]


---

### What Happens When Extremists Win Primaries?

.pull-left[

Hall (2015) RDD study of House candidate ideology and vote share

- Study "close primary elections"
- Extremist candidate narrowly wins or narrowly loses their party's nomination
- When the extremist wins, does their party do worse in the general election?

]

--

.pull-right[

&lt;img src="hall.png" width="100%" style="display: block; margin: auto;" /&gt;
]


---

## Bootstrapping


.pull-left[

The main idea:

- We want to show "sampling uncertainty" in estimates

- But we are afraid of modeling assumptions about the estimate

- or there is no obvious formula for the standard error

]

--

.pull-right[
Algorithm:

- Original data contains `\(n\)` observations 

- Sample `\(n\)` observations **with replacement** (some observations sampled more than once or not at all)

- Estimate model in the resample

- Repeat many times

]



---

class: center, middle

# Conclusion

Causal inference is possible, if we do the right things

Many common econometric models **do not** give us causal estimates

Many of the variables we control for **make our models worse**

Must know which **assumptions** enable causal inference from non-experimental data

Causal inference can be improved with **computational tools** (special models, bootstrapping, matching, synthetic control, machine learning)

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

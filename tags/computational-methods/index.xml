<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computational Methods on Michael DeCrescenzo</title>
    <link>/tags/computational-methods/</link>
    <description>Recent content in Computational Methods on Michael DeCrescenzo</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Michael DeCrescenzo {year}</copyright>
    <lastBuildDate>Sun, 29 Mar 2020 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="/tags/computational-methods/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Causal Inference Reading Group
</title>
      <link>/teaching/causal-inf-2019/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/teaching/causal-inf-2019/</guid>
      <description>&lt;p&gt;Over the summer of 2019, I organized and led discussion for a semi-formal reading group on causal inference methods. Much of the material focused on &amp;ldquo;the view from political science,&amp;rdquo; but I tried to broaden the scope in particular ways. We explored DAG approaches to causal identification in addition to potential outcomes, and we went beyond research designs for causal estimands to include estimation methods aside from common regression models.&lt;/p&gt;
&lt;p&gt;The reading list below contains both the &amp;ldquo;assigned&amp;rdquo; and the &amp;ldquo;bonus&amp;rdquo; readings (without bothering to denote which is which).&lt;/p&gt;
&lt;h2 id=&#34;readings&#34;&gt;Readings&lt;/h2&gt;
&lt;p&gt;Introduction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rubin (1974), &lt;a href=&#34;http://www.fsb.muohio.edu/lij14/420_paper_Rubin74.pdf&#34;&gt;&amp;ldquo;Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LaLonde (1986), &lt;a href=&#34;https://www.jstor.org/stable/pdf/1806062.pdf?casa_token=F5r8Z1JwiHMAAAAA:dJ7TKfvXSkhNZWr20eLIV3V7v1SuPWSh-i_98wRQl3jf4gadsB-K8UsSiWV2-QcaEj4AUR6Bpg2yG5e3wH6SRsIxEzqwzuxY5ySQ1DyE8rUqpNo8Wg&#34;&gt;&amp;ldquo;Evaluating the Econometric Evaluations of Training Programs with Experimental Data&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;McElreath (2019), &lt;a href=&#34;https://youtu.be/l_7yIUqWBmE&#34;&gt;&amp;ldquo;Statistical Rethinking 2019&amp;rdquo; Lecture 6 (DAGs)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Aronow and Samii (2016), &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12185?casa_token=ni-7Ez1IOr0AAAAA:iaBEJKWKDCduQDQjgE1YOtbkJTtSDO9Z6-xlY7PreUPM4IzwJ634U9kZvovCAGE_25W4shlhNKnGJrQ&#34;&gt;&amp;ldquo;Does Regression Produce Representative Estimates of Causal Effects?&amp;quot;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Causal Identification&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holland (1986), &lt;a href=&#34;https://www.jstor.org/stable/pdf/2289064.pdf?casa_token=t__em5YLS3QAAAAA:bRijEbuXZ1vc8wndntsVlUSkP8HGfHtd5gzBT7xGuvtMQ4bbpxATiou0wIcWv-h7TsFeISmNgAWK3MywsZD3izZ7dlknR_Lu6iCTo-xVP4ZlZPcJ8w&#34;&gt;&amp;ldquo;Statistics and Causal Inference&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kang and Schafer (2007), &lt;a href=&#34;https://projecteuclid.org/download/pdfview_1/euclid.ss/1207580167&#34;&gt;&amp;ldquo;Demystifying Double Robustness: A Comparison of Alternative Strategies for Estimating a Population Mean from Incomplete Data&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Sekhon (2007), &lt;a href=&#34;https://www.researchgate.net/profile/Henry_Brady/publication/255476843_The_Neyman-Rubin_Model_of_Causal_Inference_and_Estimation_Via_Matching_Methods/links/54d8dd670cf25013d0405ce3/The-Neyman-Rubin-Model-of-Causal-Inference-and-Estimation-Via-Matching-Methods.pdf&#34;&gt;&amp;ldquo;The Neyman-Rubin Model of Causal Inference and Estimation via Matching Methods&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stuart (2010), &lt;a href=&#34;https://projecteuclid.org/download/pdfview_1/euclid.ss/1280841730&#34;&gt;&amp;ldquo;Matching methods for causal inference: A review and a look forward&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bowers, Fredrickson, and Panagopoulos (2013), &lt;a href=&#34;https://www.jstor.org/stable/pdf/23359695.pdf?casa_token=wI0j9lMiDx0AAAAA:tnvEGu14_-fGNjbUZxLq0ln9foKBOd85zKIor3nQYj3pwxo4ch_wXQyZ_qeTSBxngpQjfOBNZwKr3ARWj1uBjGbnxWQ7LFyTWHZGX7og8udmimMLGA&#34;&gt;&amp;ldquo;Reasoning about Interference Between Units: A General Framework&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hartman, Grieve, Ramsahai, and Sekhon (2015), &lt;a href=&#34;https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssa.12094&#34;&gt;&amp;ldquo;From sample average treatment effect to population average treatment effect on the treated: combining experimental with observational studies to estimate population treatment effects&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Keele (2015), &lt;a href=&#34;https://www.jstor.org/stable/pdf/24573164.pdf?casa_token=o7xKm1U2WtUAAAAA:auheq_VJJPJA_i92nhwMo0gPZAKS7NeVL9qgsAsXi2JQk0UYqInRMaVmF-EY14Siq4eS1-ZmIaSj30Dr3trXzWbzEWeoEvhNeQVT42vGxAxGqIyTQw&#34;&gt;&amp;ldquo;The statistics of causal inference: A view from political methodology&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hartman and Hidalgo (2018), &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12387?casa_token=fuTLoS2dIhgAAAAA:MTLN-y62YNdgtSmT7lDUAO3z4zvDsDpjGdTrwwwYbxgD4vYqJXcCTmjgtw5RxeDouIzNFrlXNmsiFw&#34;&gt;&amp;ldquo;An equivalence approach to balance and placebo tests&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Causal Mediation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Imai, Keele, Tingley, and Yamamoto (2010), &lt;a href=&#34;https://www.jstor.org/stable/pdf/23275352.pdf?casa_token=ijN2lRaBMnMAAAAA:Bcg68xjAPuuy-8adQxtg0fkSYL2GZqy2pAOcQj6r7aJkl3mqyQYv1qIGm_ZzLAhGD46PhBPXy_vt3vqRhr2YondO4BjuNkQzKsTz43iXYcYg11XxzA&#34;&gt;&amp;ldquo;Unpacking the black box of causality: Learning about causal mechanisms from experimental and observational studies&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;VanderWeele and Vansteelandt (2015), &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4287269/pdf/nihms-633002.pdf&#34;&gt;&amp;ldquo;Mediation Analysis with Multiple Mediators&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Myers and Tingley (2016), &lt;a href=&#34;https://www.cambridge.org/core/journals/political-analysis/article/influence-of-emotion-on-trust/2A90FCCAA46B8EF2B41308C7C80E876B&#34;&gt;&amp;ldquo;The Influence of Emotion on Trust&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Causal Heterogeneity&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kam and Trussler (2017) &lt;a href=&#34;https://link.springer.com/content/pdf/10.1007%2Fs11109-016-9379-z.pdf&#34;&gt;&amp;ldquo;At the Nexus of Observational and Experimental Research: Theory, Specification, and Analysis of Experiments with Heterogeneous Treatment Effects&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Coppock, Leeper, and Mullinix (2017), &lt;a href=&#34;https://www.pnas.org/content/pnas/115/49/12441.full.pdf&#34;&gt;&amp;ldquo;Generalizability of heterogeneous treatment effect estimates across samples&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Meager (2019), &lt;a href=&#34;http://eprints.lse.ac.uk/88190/1/app.20170299.pdf&#34;&gt;&amp;ldquo;Understanding the Average Impact of Microcredit Expansions: A Bayesian Hierarchical Analysis of Seven Randomized Experiments&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Null Effects and Statistical Power&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mayo (2004), &lt;a href=&#34;https://www.phil.vt.edu/dmayo/personal_website/evidence_MAYO_opt.pdf&#34;&gt;&amp;ldquo;An error-statistical philosophy of evidence&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Broockman (2014), &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0261379413001583&#34;&gt;&amp;ldquo;Do female politicians empower women to vote or run for office? A regression discontinuity approach&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gelman and Carlin (2014), &lt;a href=&#34;https://journals.sagepub.com/doi/pdf/10.1177/1745691614551642&#34;&gt;&amp;ldquo;Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bhavnani (2017), &lt;a href=&#34;https://pubs.aeaweb.org/doi/pdfplus/10.1257/app.20160030&#34;&gt;&amp;ldquo;Do the Effects of Temporary Ethnic Group Quotas Persist? Evidence from India&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Coppenolle (2017), &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/epdf/10.1111/lsq.12164&#34;&gt;&amp;ldquo;Political Dynasties in the UK House of Commons: The Null Effect of Narrow Electoral Selection&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Loken and Gelman (2017), &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/measurement.pdf&#34;&gt;&amp;ldquo;Measurement error and the replication crisis&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fowler (2019), &lt;a href=&#34;https://thepoliticalmethodologist.com/2019/05/24/but-shouldnt-that-work-against-me/&#34;&gt;&amp;ldquo;But Shouldn’t That Work Against Me?&amp;quot;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;G-Methods&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Naimi, Cole, and Kennedy (2017), &lt;a href=&#34;https://watermark.silverchair.com/dyw323.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAjowggI2BgkqhkiG9w0BBwagggInMIICIwIBADCCAhwGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMlLYhK-XfIUHDcRhIAgEQgIIB7Xps8vAzzNwv6RuE8NwHCHcE_n_w0UzDvZlYG5u0NhLLLspOzyfJjN1PbwTCUcf1zlFZ_uXQzVn8ObXIX3WwZl-9v-WYtAetq3Kf6709OeSsaQhyFo8ssXvhor-qfJ4D4zwJpCFi58sm95sQ73Ifn1z1hzUgKuNFe_xaBwP2Zkd4va0yUYj3IIzHLU6y9sauuxbWKvALysdW8se9PQdzON_lfyPTAEGLx1katG9k0kRdABGcrOL0ODhTlZHc-uODteK-jwFYqOp36qKOl1prnINhTpBVaoUKPiBqC_Rs0rzsEKBPmYtg3-0glrCi9cssBQ5L9id5v3UskEZ3immwewUuqKuHbf-1SLzTGFmBLt6u8GdOZZzLTT32mRduX-rueaZoSHD8gAE1xq123-bBTO3W7rdD2yWgG6tkTGFux91vGRhMd9PxerJ1k5UU_382jz5PomFArHwp3pwowr3INn_5Q7xlrd_OhPh0G0vyps2xQu2b9HugYVOfJVR3OBV2u9BINUCMpIhaVL3rS8ePByFhjaQVGF2iSzS7iqQ9tCIlH7xf2hSfiHjztJAGw09NkIxTyTt_Nj8HHk2wih2OMIiKhXGXlXpVYxha6m_lKDldSb_XUBQqDvCGcoUIVGVV7eFtcLkdpTq_VY-BJMw&#34;&gt;&amp;ldquo;An introduction to g methods&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Acharya, Blackwell, and Sen (2016), &lt;a href=&#34;https://pdfs.semanticscholar.org/553b/d629b87aab05781cca1f3b0e42358d74fbda.pdf&#34;&gt;&amp;ldquo;Explaining Causal Findings Without Bias: Detecting and Assessing Direct Effects&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DAGs (1)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Greenland, Pearl, Robins (1999), &lt;a href=&#34;https://ftp.cs.ucla.edu/pub/stat_ser/r251.pdf&#34;&gt;&amp;ldquo;Causal Diagrams for Epidemiological Research&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Keele, Stevenson, and Elwert (2019) &lt;a href=&#34;https://www.cambridge.org/core/services/aop-cambridge-core/content/view/4488EC8925CF8F623CDE655E01268F6F/S2049847019000311a.pdf/causal_interpretation_of_estimated_associations_in_regression_models.pdf&#34;&gt;&amp;ldquo;The causal interpretation of estimated associations in regression models&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DAGs (2)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VanderWeele and Robins (2014) &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4239133/pdf/nihms632478.pdf&#34;&gt;&amp;ldquo;Signed directed acyclic graphs for causal inference&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Mohan and Pearl (2014), &lt;a href=&#34;https://papers.nips.cc/paper/5575-graphical-models-for-recovering-probabilistic-and-causal-queries-from-missing-data.pdf&#34;&gt;&amp;ldquo;Graphical Models for Recovering Probabilistic and Causal Queries from Missing Data&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Imbens (2019), &lt;a href=&#34;https://arxiv.org/abs/1907.07271&#34;&gt;&amp;ldquo;Potential Outcome and Directed Acyclic Graph Approaches to Causality: Relevance for Empirical Practice in Economics&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lattimore and Rohde (2019), &lt;a href=&#34;https://arxiv.org/pdf/1906.07125.pdf&#34;&gt;&amp;ldquo;Replacing the do-calculus with Bayes rule&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Machine Learning&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hastie, Tibshirani, and Friedman (2009) &lt;a href=&#34;https://web.stanford.edu/~hastie/Papers/ESLII.pdf&#34;&gt;&amp;ldquo;The Elements of Statistical Learning Data Mining, Inference, and Prediction (2 ed.)&amp;quot;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hill (2011), &lt;a href=&#34;https://www.tandfonline.com/doi/pdf/10.1198/jcgs.2010.08162?casa_token=LzuXt92SeEoAAAAA:KW4xyog-6_yOMM7B5zPiqpHdUQv7eLIf0fIdHPTKMxv5FHX5mfbnb9hQnjc2EzLhU_4FjY3lh5E&#34;&gt;&amp;ldquo;Bayesian Nonparametric Modeling for Causal Inference&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Samii, Paler, and Daly (2016), &lt;a href=&#34;https://www.cambridge.org/core/journals/political-analysis/article/retrospective-causal-inference-with-machine-learning-ensembles-an-application-to-antirecidivism-policies-in-colombia/B27477770599A4CE0ACB9204685EA95B&#34;&gt;&amp;ldquo;Retrospective causal inference with machine learning ensembles: An application to anti-recidivism policies in Colombia&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wager and Athey (2018), &lt;a href=&#34;https://www.tandfonline.com/doi/pdf/10.1080/01621459.2017.1319839?needAccess=true&#34;&gt;&amp;ldquo;Estimation and Inference of Heterogeneous Treatment Effects using Random Forests&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Abraham and Sun (2019), &lt;a href=&#34;http://economics.mit.edu/files/14964&#34;&gt;&amp;ldquo;Estimating Dynamic Treatment Effects in Event Studies with Heterogeneous Treatment Effects&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Cheng, Khomtchouk, Matloff, and Mohanty (2019), &lt;a href=&#34;https://arxiv.org/pdf/1806.06850.pdf&#34;&gt;&amp;ldquo;Polynomial Regression as an Alternative to Neural Nets&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hahn, Murray, and Carvalho (2019), &lt;a href=&#34;https://arxiv.org/pdf/1706.09523.pdf&#34;&gt;&amp;ldquo;Bayesian Regression Tree Models for Causal Inference: Regularization, Confounding, and Heterogeneous Effects&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;McElreath (2019), &lt;a href=&#34;https://youtu.be/pwMRbt2CbSU&#34;&gt;&amp;ldquo;Statistical Rethinking 2019&amp;rdquo; Lecture 19 (Gaussian Processes)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Regression Discontinuity&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Calonico, Cattaneo, and Titiunik (2014), &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/pdf/10.3982/ECTA11757?casa_token=ReSBtC9lfNsAAAAA:i6a-m-R6qyB0wsn5v1Y76d0MrIEalQO-QuXiknTrJCCXBXbxxWLNXyV092CCROUyWlO8gAiXrP2Nvw&#34;&gt;&amp;ldquo;Robust Nonparametric Confidence Intervals for Regression-discontinuity Designs&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Caughey and Sekhon (2014), &lt;a href=&#34;http://zmjones.com/static/causal-inference/caughey-pa-2011.pdf&#34;&gt;&amp;ldquo;Elections and the regression discontinuity design: Lessons from close US house races, 1942–2008&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Skovron and Titiunik (2015), &lt;a href=&#34;https://pdfs.semanticscholar.org/5461/c817976f51a4fb0073b772c03cd670be8def.pdf&#34;&gt;&amp;ldquo;A Practical Guide to Regression Discontinuity
Designs in Political Science&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Imbens and Wager (2019), &lt;a href=&#34;https://www.mitpressjournals.org/doi/pdfplus/10.1162/rest_a_00793?casa_token=fhbRGkrXL4EAAAAA:UpisrmCWbq4jGpVRfrdNcSqRxbaFmPDuK6f6P17oSu4XQCY2UFaj0mNIVdHkxjVIaZItXKCv&#34;&gt;&amp;ldquo;Optimized Regression Discontinuity Designs&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Time-Series Cross-Sectional and Panel Data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blackwell and Glynn (2018), &lt;a href=&#34;https://www.cambridge.org/core/journals/american-political-science-review/article/how-to-make-causal-inferences-with-timeseries-crosssectional-data-under-selection-on-observables/498BE04E5AF9802EC4D33DD7A4016584&#34;&gt;&amp;ldquo;How to Make Causal Inferences with Time-Series Cross-Sectional Data under Selection on Observables&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Goodman-Bacon (2018), &lt;a href=&#34;https://cdn.vanderbilt.edu/vu-my/wp-content/uploads/sites/2318/2019/04/14141044/ddtiming_9_5_2018.pdf&#34;&gt;&amp;ldquo;Difference-in-Differences with Variation in Treatment Timing&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Torres (2019), &lt;a href=&#34;https://www.dropbox.com/s/872jdkg3dgo8ics/MSM_PSRM_2.pdf?dl=0&#34;&gt;&amp;ldquo;Estimating Controlled Direct Effects Through Marginal Structural Models&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>PS 270: Understanding Political Numbers
</title>
      <link>/teaching/numbers/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/teaching/numbers/</guid>
      <description>&lt;p&gt;Data are increasingly prevalent in politics (and in journalism, industry, academia&amp;hellip;), but data are complex and challenging. What can we learn about politics, and the social world more broadly, when we take an empirical view of it? When should we trust data, and when will data lead us astray?&lt;/p&gt;
&lt;p&gt;Political science 270 is an undergraduate course on consuming, criticizing, and producing data-driven analysis of political and social phenomena. Students learn to think about political data as evidence for or against social theories. The course emphasis practical data analysis skills that apply beyond the political science curriculum, including elementary statistical analysis, R programming (&lt;code&gt;Rstudio&lt;/code&gt;, &lt;code&gt;tidyverse&lt;/code&gt;, &lt;code&gt;ggplot2&lt;/code&gt;), and technical writing.&lt;/p&gt;
&lt;p&gt;View course materials on &lt;a href=&#34;https://github.com/mikedecr/political-numbers-s19/&#34;&gt;&lt;code&gt;Github&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PS 811: Introductory Statistical Computing for Political Science
</title>
      <link>/teaching/computing-811/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/teaching/computing-811/</guid>
      <description>&lt;h1 id=&#34;2020-materials&#34;&gt;2020 Materials&lt;/h1&gt;
&lt;p&gt;View syllabus &lt;a href=&#34;/courses/811/ps811-s20-syllabus.pdf&#34;&gt;here&lt;/a&gt;. Weekly materials below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introduction. &lt;a href=&#34;/teaching/computing-811/slides/01-intro/01-intro.html&#34;&gt;[Slides]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Projects &amp;amp; Intro R Markdown. &lt;a href=&#34;/teaching/computing-811/slides/02-rmd-proj/02-rmd-proj.html&#34;&gt;[Slides]&lt;/a&gt; &lt;a href=&#34;https://github.com/mikedecr/example-project&#34;&gt;[Example Project]&lt;/a&gt; &lt;a href=&#34;https://github.com/mikedecr/PS811-computing/blob/master/code/Rmd/rmarkdown-demo.Rmd&#34;&gt;[Rmd Demo]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Basics of R. &lt;a href=&#34;https://github.com/mikedecr/PS811-computing/blob/master/code/01_basics.R&#34;&gt;[Script]&lt;/a&gt; &lt;a href=&#34;https://github.com/mikedecr/PS811-computing/blob/master/assignments/skill-1/skill-task-1.pdf&#34;&gt;[Homework]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Data Manipulation (&lt;code&gt;tidyverse&lt;/code&gt;/&lt;code&gt;dplyr&lt;/code&gt;). &lt;a href=&#34;https://github.com/mikedecr/PS811-computing/blob/master/code/02_data-manipulation.R&#34;&gt;[Script]&lt;/a&gt; &lt;a href=&#34;https://github.com/mikedecr/PS811-computing/blob/master/assignments/skill-2/skills-task-2.pdf&#34;&gt;[Homework]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Graphics (&lt;code&gt;ggplot2&lt;/code&gt;). &lt;a href=&#34;https://github.com/mikedecr/PS811-computing/blob/master/code/03_graphics.R&#34;&gt;[Script]&lt;/a&gt; &lt;a href=&#34;https://github.com/mikedecr/PS811-computing/blob/master/assignments/skill-3/skills-task-3.pdf&#34;&gt;[Homework]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Regression (&lt;code&gt;broom&lt;/code&gt;). &lt;a href=&#34;/teaching/computing-811/slides/04_regression/04_regression.html&#34;&gt;[Slides]&lt;/a&gt; &lt;a href=&#34;https://github.com/mikedecr/PS811-computing/blob/master/code/04_regression.R&#34;&gt;[Script]&lt;/a&gt; &lt;a href=&#34;https://github.com/mikedecr/PS811-computing/blob/master/assignments/skill-4/skills-task-4.pdf&#34;&gt;[Homework]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;2018-materials&#34;&gt;2018 materials&lt;/h1&gt;
&lt;p&gt;In 2018, this course was split between R and Stata. I covered the R unit, and &lt;a href=&#34;https://miamioh.edu/cas/academics/departments/political-science/about/faculty-staff/faculty-bios/chapman/index.html&#34;&gt;Hannah Chapman&lt;/a&gt; covered Stata.&lt;/p&gt;
&lt;p&gt;R notes for 2018 are &lt;a href=&#34;/courses/811&#34;&gt;here&lt;/a&gt;, and the source code (&lt;code&gt;.rmd&lt;/code&gt; files) for these workbooks are &lt;a href=&#34;https://github.com/mikedecr/site-leavit/tree/master/content/811&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graduate Math Camp (UW–Madison Political Science)
</title>
      <link>/teaching/math-camp/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/teaching/math-camp/</guid>
      <description>&lt;p&gt;I have two years of experience teaching the UW political science &amp;ldquo;math bootcamp&amp;rdquo; for incoming graduate students. My most recent materials (2018) are open-source on &lt;a href=&#34;https://github.com/mikedecr/math-camp-2018&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graduate $\mathrm{\LaTeX}$ Workshop (UW–Madison Political Science)
</title>
      <link>/teaching/latex-workshop/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/teaching/latex-workshop/</guid>
      <description>&lt;p&gt;Every year, the UW Political Science department holds a $\mathrm{\LaTeX}$ workshop&amp;mdash;a few introductory training sessions for graduate students on document preparation. I have been involved with organizing this workshop since 2015, and have been leading it since 2017.&lt;/p&gt;
&lt;p&gt;All materials for the worksho, source code and all, are publicly available (in their 2018 vintage) on my &lt;a href=&#34;https://github.com/mikedecr/latex-workshop-2018&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Plotting What Matters</title>
      <link>/post/visualizing-what-matters/</link>
      <pubDate>Sun, 29 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/visualizing-what-matters/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;this-is-a-post-about-temptation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;This is a post about temptation&lt;/h1&gt;
&lt;p&gt;Or, resisting temptations when presenting statistical results.&lt;/p&gt;
&lt;p&gt;When you build a model to answer a question, it is often tempting to make a graphic about the &lt;em&gt;coolest thing about the model&lt;/em&gt;. Maybe you learned something new to build the model, or you noticed and corrected an important structure in the data, so naturally you want to show off your good work. The purpose of this post is to &lt;strong&gt;reflect on why this practice isn’t useful for communicating statistical results&lt;/strong&gt;. Instead, we should be communicating the information that will help the audience grasp the important takeaways of the analysis. A different focus entirely.&lt;/p&gt;
&lt;p&gt;This is almost too obvious, but it is easier said than done. Researchers wrestle with it in different ways based on our audiences, our professional goals, and (to be honest) our insecurities. Speaking for myself, I need to grapple with my biases and how they manifest in my work product. As a PhD student, I sometimes feel like academia cultivates incentives to convince our colleagues that we are Very Smart&lt;sup&gt;TM&lt;/sup&gt;, which is a distinct goal from doing good work (however defined). Cool graphics can be a way to show how much thought and work we put into something—a way of signaling that we belong. Understandable, but not always useful. I also like to use Bayesian methods, but I feel constant pressure to justify the Bayesian approach to audiences that I (rightly or wrongly) assume will be hostile to that choice. As a result, I feel tempted to plot something that would be impossible without Bayes—a way of saying, “Get off my back!” as if it ultimately mattered for what I’m trying to communicate with my analysis overall. Sometimes it does matter, but the way that it matters won’t be so simple as “just plot the flashy thing.”&lt;/p&gt;
&lt;p&gt;This post unpacks this using a recent example from a grad methods course that I am TA’ing. The assignment requires students to write a policy memo informed by a statistical analysis. The statistical model contains an important component that students are learning about in the course, but that component &lt;strong&gt;isn’t actually important to communicate in the policy memo&lt;/strong&gt;. So the assignment challenges students both on model-building but also communication skills: exercising restraint and judgment about what is and is not important to communicate about the details of the analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-setting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The setting&lt;/h1&gt;
&lt;p&gt;The assignment for students to complete lays out the following scenario.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You are an advisor to a newly elected mayor of Smallville. During the campaign, the mayor-elect charged that the Sanitation Department was being grossly mismanaged. Last year it cost &lt;span class=&#34;math inline&#34;&gt;\(\$ 48.50\)&lt;/span&gt; per household for once-a-week curbside waste pick-up. A private contractor has made an informal bid of &lt;span class=&#34;math inline&#34;&gt;\(\$ 40.60\)&lt;/span&gt; per household for collection services, but this would require eliminating Sanitation Department jobs, which would be difficult and politically costly. Before switching to private contracting, the mayor would like to know how much costs might be reduced with the appointment of a more competent Sanitation Department supervisor.&lt;/p&gt;
&lt;p&gt;Prepare a memorandum to the mayor advising her about the potential gains from better management. The mayor has had little statistical training, so be sure to explain your empirical work clearly and carefully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Students are given a dataset of 30 other municipalities in the region, simulated from a model that they don’t directly see.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 5
##    hholds density  wage snowdays cost_per_household
##     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;              &amp;lt;dbl&amp;gt;
##  1   3.35    565.  18.2        3               29.4
##  2  11.2     740.  15.7       10               52.0
##  3   9.48    540.  17.4        3               34.4
##  4   9.43    629.  19.6        1               41.5
##  5  11.3     685.  20.6        6               63.4
##  6   6.18    605.  20.2        6               30.0
##  7   2.82    510.  16.5        4               20.8
##  8   2.95    459.  15.8        2               12.9
##  9   6.98    507.  16.5        3               21.8
## 10   7.89    524.  19.9        2               37.8
## # … with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variables are described as follows.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cost_per_household&lt;/code&gt;: cost per household (&lt;span class=&#34;math inline&#34;&gt;\(\$\)&lt;/span&gt; U.S.) of once weekly curbside refuse pickup for last year.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hholds&lt;/code&gt;: number of households served in 10,000s. &lt;strong&gt;(Note: previous studies suggest refuse collection may involve non-constant returns to scale; that is, there may be some number of households at which the cost per household is minimized; communities with smaller or larger numbers of households have higher costs per household.)&lt;/strong&gt; Value for your city: 6.28.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;density&lt;/code&gt;: density of households per square mile. Value for your city: 620.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wage&lt;/code&gt;: average hourly wage in dollars for collection workers. Value for your city: 19.50.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;snowdays&lt;/code&gt;: number of snow emergency days last year; may raise costs by interfering with regular schedule. Value for your city: 5.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;So what’s the objective?&lt;/strong&gt; Students are supposed to use the data to build a predictive (OLS) model for &lt;code&gt;cost_per_household&lt;/code&gt;, and then interpret the model to advise the mayor about the choice between (a) enlisting the private sanitation contractor or (b) replacing the supervisor of the Sanitation Department.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;source-of-temptation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Source of temptation&lt;/h1&gt;
&lt;p&gt;Students typically begin with a simple model where every variable is linearly related to the outcome variable…
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
  \mathtt{cost\_per\_household}_{i} &amp;amp;= 
    \alpha + 
    \beta_{1} \mathtt{hholds} +
    \beta_{2} \mathtt{density} \\
  &amp;amp; \quad 
    + \beta_{3} \mathtt{wage} +
    \beta_{4} \mathtt{snowdays} +
    \varepsilon_{i}
\end{align}\]&lt;/span&gt;
…with a normally distributed error. But they should find that the simple model violates OLS assumptions by producing residuals with a curvilinear pattern. If students inspect the data more, they detect that the likely culprit is the &lt;code&gt;hholds&lt;/code&gt; variable, the number of households in the municipality. This is consistent with the hint in the variable descriptions above, that there may be some number of households that minimize sanitation costs per household. So they build a model with a quadratic term for &lt;code&gt;hholds&lt;/code&gt;.
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
  \mathtt{cost\_per\_household}_{i} &amp;amp;= 
    \alpha + 
    \beta_{1} \mathtt{hholds} +
    \beta_{2} \mathtt{hholds}^{2} +
    \beta_{3} \mathtt{density} \\
  &amp;amp; \quad 
    + \beta_{4} \mathtt{wage} +
    \beta_{5} \mathtt{snowdays} +
    \varepsilon_{i}
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For the purposes of the assignment, this is the “correct” model, and the residuals look better than they did before (see below).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-28_viz-choices_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now that we have the appropriate model, how do we visualize it? I’ll tell you what I did when I was a student in this course (many years ago): I plotted the nonlinear relationship between the number of households and the outcome variable. It the most interesting part of the model, and it was hidden in the data…how could it not be the important thing that I should focus on? I think I did something like this: generate model predictions with other variables fixed at their means, and then plot those model predictions alongside my city’s data (Smallville) and the private contractor’s proposal for reducing the curbside pickup costs per household.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-28_viz-choices_files/figure-html/wrong-plot-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From this graphic, we could reason that even if we enlist the private contractor, their bid does not get us close to what we would expect from the model. This leads us the direction of saying that maybe we expect more savings from better mismanagement of the Sanitation Department than what the current supervisor is delivering.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;disciplined-plotting-choices&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Disciplined plotting choices&lt;/h1&gt;
&lt;p&gt;There are a few things that are misguided about the above approach.&lt;/p&gt;
&lt;p&gt;First, the comparison in this above graphic isn’t actually the relevant comparison. It is typical to teach students to visualize partial relationships in regression by varying one predictor and fixing other predictors to their means. But we don’t always want to compare against a typical observation. In this example, we would be more interested in holding covariates to the same values as we observe for our city. Applied situations like this remind us that many of the problems that we encounter aren’t questions about “typical” observations at all.&lt;/p&gt;
&lt;p&gt;Second, and more importantly, the only reason why we make the previous mistake is because we think that the quadratic relationship is the important thing to visualize. It’s understandable that we’re distracted by the quadratic relationship because it was initially a challenge to discover, but if we discipline ourselves about what is important to communicate to our audience (in this case, the mayor of “Smallville”), we would see that the nonlinearity is irrelevant to visualize. All that matters is comparing our city’s data and the contractor’s proposal to a specific model-based prediction for our city. Exploring how the prediction changes as we arbitrarily assign other values on key covariates doesn’t help us make a policy recommendation. We aren’t in a position to intervene on those variables (and we aren’t confident that our model identifies causal effects anyway), so we shouldn’t distract the mayor by presenting irrelevant information that draws focus away from the key insights.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;What is a simpler way to show the model’s key takeaway? Here.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-28_viz-choices_files/figure-html/plot-smallville-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The takeaway from this figure is similar as it was above. We show a model-based prediction for a city with the same observable characteristics as Smallville (a point estimate, 95% confidence interval, and 95% prediction interval) alongside Smallville’s current costs and the contractor’s proposal.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;
We see that the contractor’s proposal reduces sanitation costs, but they still get us nowhere near a level that we should expect given the characteristics of our city. If we are confident that replacing the Sanitation Department supervisor would make our costs “representative” of other similar towns, we would save a lot more money by replacing the supervisor than we would by hiring the contractor.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-can-do-better-visualize-cost-savings-directly&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;We can do better: visualize cost-savings directly&lt;/h1&gt;
&lt;p&gt;Even though the above graphic does a little better than what we were working with before, it still doesn’t directly communicate the aggregate financial impact of the policy. The audience has to do that work on their own still. If we really wanted to communicate the insights of the model, we could translate these predictions directly into something that mayors, comptrollers, and so on really understand: dollars.&lt;/p&gt;
&lt;p&gt;Here’s the idea. In terms of annual cost cost-per-household, we know our city’s current value, the contractor’s bid, and a distribution of model-based estimates for a city with our data. We also know the total number of households in our city, so it is straightforward to calculate the total costs from each of these per-household figures:
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
  \text{Total annual cost} &amp;amp;= \text{Cost per household} \times \text{Number of households}
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So we calculate annual costs for the current per-household rate, the contractor’s bid, and three model-based scenarios&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;
that result from replacing the Sanitation Dept. supervisor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An “average” scenario: plugging in the point estimate from the model as the annual cost per household under a new supervisor.&lt;/li&gt;
&lt;li&gt;An “optimistic” scenario: plugging in the 10th percentile of the predictive distribution as the estimated cost per household.&lt;/li&gt;
&lt;li&gt;A “pessimistic” scenario: plugging in the 90th percentile of the predictive distribution as the annual cost per household.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We plot two quantities for each scenario. First, how much money is saved annually by replacing the supervisor brings pickup costs to each of these benchmarks? And second, how much &lt;em&gt;more&lt;/em&gt; does each benchmark save us when we compare to the private contractor’s bid?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-28_viz-choices_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The comparison against the contractor bid isn’t just for show! It gives decision-makers valuable information because it represents a “budget” for replacing the supervisor. How so? Replacing the supervisor wouldn’t be costless: the replacement may require a higher salary than the current supervisor, and the job search will involve some fixed costs. Comparing each scenario’s savings to the amount saved from the enlisting the contractor conveys how much money we can &lt;em&gt;invest&lt;/em&gt; in a new supervisor while still saving more money than hiring the contractor. Visualizing the results this way shows exactly how much money we’re working with and how much we stand to save by hiring supervisors with different salary expectations.&lt;/p&gt;
&lt;p&gt;By doing some further processing of the model’s insights, and in-turn moving &lt;em&gt;farther&lt;/em&gt; from the technical details of the model, we actually learn more about the consequences of our choices. We see that even under the pessimistic cost-savings scenario, we still have a roughly half-million dollar cushion before the decision to replace the supervisor starts to look like the wrong choice.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reframing-what-to-be-proud-of&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reframing what to be “proud” of&lt;/h1&gt;
&lt;p&gt;We feel proud when we build a technologically complex model. It makes us feel valuable when we work through something challenging, so we want to show it off. When we need to hide these technical details in order to communicate the results to non-experts, the choice is painful at first, especially for someone like me who takes a lot of pride in the time and effort that I invest in improving my statistical skills. This is a psychological game that we are playing with ourselves.&lt;/p&gt;
&lt;p&gt;But the “difficulty-level” of our work isn’t the only skill to take pride in. Distilling essential information out of a complicated piece of machinery is valuable, and we can see it as a distinct source of pride when we do it well. Better still, doing an effective job summarizing the important takeaways of an analysis makes it all the more rewarding to describe the technical backend, since the technical backend has a much stronger clarity-of-purpose after if is introduced effectively.&lt;/p&gt;
&lt;p&gt;Just to drive the point home, that last graph was a bar graph. I kinda hate bar graphs. But I don’t hate the fact that I recognized a context where it made something simpler to communicate. That’s valuable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;
At this point you may wonder if we can intervene on the system by reducing the wages of sanitation workers to make up the cost difference. First of all, how dare you. Secondly, even though we know that lowering wages should have a causal effect on pickup costs, we don’t know that the coefficient for &lt;code&gt;wage&lt;/code&gt; in the model represents the causal effect of wages—certainly it doesn’t. Third, even if we could make that assumption, the numerical impact of decreasing sanitation worker wages to (say) the median wage for other cities would amount to only $5.54 saved per household, so we save even less than we would save from hiring the contractor.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;
The language used in the graphic (“95% range of predictions”) is doing a little violence against the meaning of a frequentist confidence interval. If I were implementing this analysis in real life, I would build a Bayesian model that lets me say, “This is the likely range of scenarios, as the data suggest,” because that’s conveniently what a posterior distribution actually means!&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;
Once again, interpreting the prediction interval as “possible scenarios” is more closely tied to Bayes than to a frequentist model. The more I think about the value of communicating model predictions as “possible scenarios,” the more I think this warrants its own blog post. &lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Purrrmutation Testing</title>
      <link>/post/randomization-inference-purrr/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/randomization-inference-purrr/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;style type=&#34;text/css&#34;&gt;
pre &gt; code.sourceCode { white-space: pre; position: relative; }
pre &gt; code.sourceCode &gt; span { display: inline-block; line-height: 1.25; }
pre &gt; code.sourceCode &gt; span:empty { height: 1.2em; }
code.sourceCode &gt; span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre &gt; code.sourceCode { white-space: pre-wrap; }
pre &gt; code.sourceCode &gt; span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code &gt; span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code &gt; span &gt; a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre &gt; code.sourceCode &gt; span &gt; a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
&lt;/style&gt;


&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;p&gt;Permutation testing (or “randomization inference,” RI) is an approach to statistical inference based on hypothetical allocations of treatment rather than sampling error. It has an appealing intuition, but researchers may feel intimidated by the prospect of implementing it computationally. Although helpful packages exist for conducting permutation tests in R,&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;
my goal for this post is to show that &lt;code&gt;tidyverse&lt;/code&gt; tools (in particular, functional programming with &lt;code&gt;purrr&lt;/code&gt;) make it easy to implement randomization inference in R flexibly and efficiently.&lt;/p&gt;
&lt;p&gt;Below I provide a brief overview of RI’s logic, implement a simple permutation test for a single treatment, and then demonstrate how to incorporate additional design features such as blocking or clustered randomization into the workflow. We will see that many of these design features are easily translated into &lt;code&gt;tidyverse&lt;/code&gt; dialect without warping or overextending the workflow into something unrecognizable or impractical.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-randomization-inference&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is Randomization Inference&lt;/h1&gt;
&lt;p&gt;Randomization inference is a method for conducting statistical hypothesis tests without making distributional assumptions about test statistics. Like all null hypothesis tests, it is a comparison between (1) an estimated effect or relationship from observed data and (2) a “null distribution” of estimates that we might have observed if the null hypothesis were true. Unlike traditional null hypothesis tests, however, the null distribution is not based on repeated sampling of a hypothetical population. Instead, it is constructed by imagining &lt;em&gt;other ways that treatment may have been randomly allocated&lt;/em&gt; among units.&lt;/p&gt;
&lt;p&gt;For instance, suppose we had some small sample of data for &lt;span class=&#34;math inline&#34;&gt;\(n = 6\)&lt;/span&gt; units. We randomly assign half of the units to treatment and half to control:&lt;/p&gt;
&lt;!-- centering this table --&gt;
&lt;center&gt;
&lt;table style=&#34;width:40%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;6%&#34; /&gt;
&lt;col width=&#34;16%&#34; /&gt;
&lt;col width=&#34;16%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;ID&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Treatment&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Outcome&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y_1\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y_2\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y_3\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y_4\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y_5\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y_6\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p&gt;We could use this data to calculate some difference in means &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta} = \bar{Y}_{1} - \bar{Y}_{0}\)&lt;/span&gt;. How do we form an inference about &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; from &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}\)&lt;/span&gt;? Typically we would standardize &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}\)&lt;/span&gt; and compare it against a &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution, finding a &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value that represents “the probability of obtaining some other &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}&amp;#39;\)&lt;/span&gt; at least as extreme as &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}\)&lt;/span&gt;, under the null hypothesis that the true &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; is zero.” Under this approach, this &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution serves as our “null distribution,” the sampling distribution of estimates that we would obtain assuming that the null is true.&lt;/p&gt;
&lt;p&gt;Randomization inference constructs this null distribution using a different method. Instead of making the parametric assumption that the standardized &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}\)&lt;/span&gt; follows a &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; distribution, we take advantage of random assignment in the research design, constructing a null distribution of treatment effect estimates by &lt;em&gt;repeatedly permuting the treatment assignments&lt;/em&gt; for our units. For example, the treatment vector in the small sample of data above was &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T} = \left[0, 0, 1, 1, 1, 0\right]\)&lt;/span&gt;, but we could have obtained a different treatment vector by random chance alone. We could have randomly realized treatment assignments as &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}&amp;#39; = \left[0, 0, 1, 0, 1, 1\right]\)&lt;/span&gt;, or &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}&amp;#39; = \left[1, 1, 1, 0, 0, 0\right]\)&lt;/span&gt;. Imagine that in each of these alternate treatment assignments, we estimate the treatment effect &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}\)&lt;/span&gt;. Under the null hypothesis, outcomes are not affected (on average) by treatment assignment, so each &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}\)&lt;/span&gt; that we estimate under the permuted treatment assignments a draw from the “null distribution” of &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}\)&lt;/span&gt;. If we could specify every possible treatment assignment, we would have a full accounting of every equally-likely null &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}\)&lt;/span&gt; estimate under the research design. This would let us calculate an “exact” &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value by comparing our in-sample estimate to the null distribution: the proportion of null estimates that are more extreme than the estimate obtained in our real data. These &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values are valid even in nonrandom samples because they operate by &lt;em&gt;design uncertainty&lt;/em&gt; instead of sampling uncertainty.&lt;/p&gt;
&lt;p&gt;More formally, suppose that random variable &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; is a test statistic that is a function of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Y}\)&lt;/span&gt;, vectors of treatment assignments and outcome data respectively (&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-5907.2011.00576.x?casa_token=YjkCBZcxieAAAAAA:-WVWyv9NfA_83dsFCKLYjofLTVBEKehe0cG3a3na-7OQhSQrURDVGsjgeKwHSv6KI5jrXpmNV5Bog9A&#34;&gt;Keele, McConnaughy, and White&lt;/a&gt;). A &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value is the probability that &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; exceeds the test statistic calculated from your data, &lt;span class=&#34;math inline&#34;&gt;\(s^{*}\)&lt;/span&gt;, given the null distribution of &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;.
&lt;span class=&#34;math display&#34; id=&#34;eq:theoretical-p&#34;&gt;\[\begin{align}
  p &amp;amp;= \mathrm{Pr}\left(S ≥ s^{*} | H_{0}\right) %*
  \tag{1}
\end{align}\]&lt;/span&gt;
A permutation test finds this &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value by calculating the test statistic for your sample of data, &lt;span class=&#34;math inline&#34;&gt;\(s^{*}\)&lt;/span&gt;, as well as test statistics &lt;span class=&#34;math inline&#34;&gt;\(s_{m}\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(m \in \mathcal{M}\)&lt;/span&gt;, treatment permutations from the set of possible treatment permutations. The &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value in the permutation test is the proportion of permuted test statistics that exceed the in-sample test statistic.
&lt;span class=&#34;math display&#34; id=&#34;eq:permute-p&#34;&gt;\[\begin{align}
  p &amp;amp;= \frac{\sum\limits_{m = 1}^{M} I(s_{m} &amp;gt; s^{*})}{M}
  \tag{2}
\end{align}\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(I(\cdot)\)&lt;/span&gt; is the indicator function and &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; is the number of permutations being considered. If &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; is equal to the total number of possible permutations, this &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value is exact. If the set of permutations &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{M}\)&lt;/span&gt; is too large to calculate every &lt;span class=&#34;math inline&#34;&gt;\(s_{m}\)&lt;/span&gt; (which is likely for even moderate samples sizes), sampling a subset of &lt;span class=&#34;math inline&#34;&gt;\(M &amp;lt; |\mathcal{M}|\)&lt;/span&gt; permutations lets you treat Equation &lt;a href=&#34;#eq:permute-p&#34;&gt;(2)&lt;/a&gt; as an approximation of the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;TLDR&lt;/em&gt;&lt;/strong&gt;, how do we perform randomization inference?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Estimate the treatment effect in our sample&lt;/li&gt;
&lt;li&gt;Compute or approximate the null distribution of the treatment effect estimate under repeated reallocations of treatment to units (conditional on the sample)&lt;/li&gt;
&lt;li&gt;Compare the in-sample estimate to its null distribution&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;randomization-inference-for-a-simple-experiment&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Randomization Inference for a Simple Experiment&lt;/h1&gt;
&lt;p&gt;This section shows how to implement permutation tests for a simple experiment with a binary treatment and binary outcome. First I describe the model used to generate data, and then we perform a permutation test using the generated data.&lt;/p&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;We will use various tools in the &lt;code&gt;tidyverse&lt;/code&gt;, so for now that is the only package we will load.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;library&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&amp;quot;tidyverse&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I simulate a dataset of &lt;span class=&#34;math inline&#34;&gt;\(n = 500\)&lt;/span&gt; units with outcome variable &lt;span class=&#34;math inline&#34;&gt;\(y_{i} \in \left\{0, 1\right\}\)&lt;/span&gt;, treatment status &lt;span class=&#34;math inline&#34;&gt;\(z_{i} \in \left\{0, 1\right\}\)&lt;/span&gt;, treatment probability &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt;. The generative model can be represented as follows:
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
  y_{i} &amp;amp;\sim \mathrm{Bernoulli}\left(0.5 + \delta z_{i}\right) \\
  z_{i} &amp;amp;\sim \mathrm{Bernoulli}\left(0.5 \right)
\end{align}\]&lt;/span&gt;
where the treatment effect &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; has a true value of &lt;span class=&#34;math inline&#34;&gt;\(0.06\)&lt;/span&gt;. In R, I generate the data like so:&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;set.seed&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;90181&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34;&gt;&lt;/a&gt;n_obs &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;500&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34;&gt;&lt;/a&gt;control_mean &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34;&gt;&lt;/a&gt;treat_effect &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;.06&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-6&#34;&gt;&lt;a href=&#34;#cb2-6&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-7&#34;&gt;&lt;a href=&#34;#cb2-7&#34;&gt;&lt;/a&gt;d &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-8&#34;&gt;&lt;a href=&#34;#cb2-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;tibble&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;id =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;:&lt;/span&gt;n_obs) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-9&#34;&gt;&lt;a href=&#34;#cb2-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb2-10&#34;&gt;&lt;a href=&#34;#cb2-10&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;treatment =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;rbernoulli&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;n =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;n&lt;/span&gt;(), &lt;span class=&#34;dt&#34;&gt;p =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;as.numeric&lt;/span&gt;(),&lt;/span&gt;
&lt;span id=&#34;cb2-11&#34;&gt;&lt;a href=&#34;#cb2-11&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;rbernoulli&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;n =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;n&lt;/span&gt;(), &lt;span class=&#34;dt&#34;&gt;p =&lt;/span&gt; control_mean &lt;span class=&#34;op&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;(treatment &lt;span class=&#34;op&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;treat_effect)) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-12&#34;&gt;&lt;a href=&#34;#cb2-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;as.numeric&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb2-13&#34;&gt;&lt;a href=&#34;#cb2-13&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-14&#34;&gt;&lt;a href=&#34;#cb2-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb2-15&#34;&gt;&lt;a href=&#34;#cb2-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 500 x 3&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-16&#34;&gt;&lt;a href=&#34;#cb2-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##       id treatment     y&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-17&#34;&gt;&lt;a href=&#34;#cb2-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-18&#34;&gt;&lt;a href=&#34;#cb2-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1     1         1     1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-19&#34;&gt;&lt;a href=&#34;#cb2-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2     2         0     0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-20&#34;&gt;&lt;a href=&#34;#cb2-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3     3         0     0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-21&#34;&gt;&lt;a href=&#34;#cb2-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4     4         1     1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-22&#34;&gt;&lt;a href=&#34;#cb2-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5     5         1     1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-23&#34;&gt;&lt;a href=&#34;#cb2-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6     6         1     1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-24&#34;&gt;&lt;a href=&#34;#cb2-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7     7         0     0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-25&#34;&gt;&lt;a href=&#34;#cb2-25&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8     8         0     1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-26&#34;&gt;&lt;a href=&#34;#cb2-26&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9     9         0     1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-27&#34;&gt;&lt;a href=&#34;#cb2-27&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10    10         0     1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-28&#34;&gt;&lt;a href=&#34;#cb2-28&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 490 more rows&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The data are a random draw from the generative model, so the treatment effect in the data won’t be exactly equal to the true effect. In these data, we estimate an in-sample treatment effect of about 0.05. We will want to save a data frame of in-sample estimates.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34;&gt;&lt;/a&gt;observed_estimates &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;d &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;summarize&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;mean_control =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;mean&lt;/span&gt;(y[treatment &lt;span class=&#34;op&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;]),&lt;/span&gt;
&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;mean_treatment =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;mean&lt;/span&gt;(y[treatment &lt;span class=&#34;op&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]),&lt;/span&gt;
&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;diff_means =&lt;/span&gt; mean_treatment &lt;span class=&#34;op&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;mean_control&lt;/span&gt;
&lt;span id=&#34;cb3-6&#34;&gt;&lt;a href=&#34;#cb3-6&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-7&#34;&gt;&lt;a href=&#34;#cb3-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb3-8&#34;&gt;&lt;a href=&#34;#cb3-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 1 x 3&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-9&#34;&gt;&lt;a href=&#34;#cb3-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##   mean_control mean_treatment diff_means&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-10&#34;&gt;&lt;a href=&#34;#cb3-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##          &amp;lt;dbl&amp;gt;          &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-11&#34;&gt;&lt;a href=&#34;#cb3-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 1        0.514          0.563     0.0495&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;permuting-treatment-assignments-tidily&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Permuting treatment assignments, tidily&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;tidyverse&lt;/code&gt; advantage comes in when we permute the treatment assignments. Ordinarily we might think about permuting treatment assignments using a for loop—for each iteration &lt;code&gt;m&lt;/code&gt; in &lt;code&gt;1:M&lt;/code&gt;, reshuffle the treatment assignments and calculate &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}_{\mathtt{m}}\)&lt;/span&gt;. Except we want to avoid a for loop because…&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For loops in R are famously slow.&lt;/li&gt;
&lt;li&gt;For loops in R are rarely necessary. For many common data wrangling problems, iteration &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; does not depend on iteration &lt;span class=&#34;math inline&#34;&gt;\(m-1\)&lt;/span&gt;, so a vectorized approach is usually more efficient.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A technical but important workflow point&lt;/strong&gt;: the data structure that results from a loop (usually a vector or a list) often throws away useful information, and it can be &lt;em&gt;organizationally idiosyncratic&lt;/em&gt; if the rest of our work is data frame-driven. If we can do this routine using a more capable data structure and extensible workflow, we have the potential to do more cool things while staying organized along the way.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We deal with points (1) and (2) by using functional programming: applying a function over groups of data (see &lt;a href=&#34;http://adv-r.had.co.nz/Functional-programming.html&#34;&gt;here&lt;/a&gt; for instance). In our case, a &lt;em&gt;group&lt;/em&gt; will be a data frame, and the &lt;em&gt;function&lt;/em&gt; is permuting the treatment assignments and estimating the treatment effect. We address point (3) by doing everything with a &lt;em&gt;nested data frame&lt;/em&gt; and applying functions to groups using &lt;code&gt;purrr::map()&lt;/code&gt;. I will describe the approach below one step at a time. After each step is explained, I will show how simple it is to combine them into a small, efficient block of readable code.&lt;/p&gt;
&lt;p&gt;The first step is to make a nested data frame: a data frame that itself contains data frames (see e.g. &lt;a href=&#34;https://blog.rstudio.com/2016/02/02/tidyr-0-4-0/&#34;&gt;[1]&lt;/a&gt;, &lt;a href=&#34;https://r4ds.had.co.nz/many-models.html&#34;&gt;[2]&lt;/a&gt;, &lt;a href=&#34;https://cran.r-project.org/web/packages/tidyr/vignettes/nest.html&#34;&gt;[3]&lt;/a&gt;). Here I create a data frame with two columns: an identifier &lt;code&gt;m&lt;/code&gt; that indexes our treatment permutations, and a data column that contains copies of our original dataset for each &lt;code&gt;m&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# total number of iterations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34;&gt;&lt;/a&gt;n_sims &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2000&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# nested data frame of all M iterations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-5&#34;&gt;&lt;a href=&#34;#cb4-5&#34;&gt;&lt;/a&gt;sim_table &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;d &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-6&#34;&gt;&lt;a href=&#34;#cb4-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;crossing&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;m =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;:&lt;/span&gt;n_sims) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-7&#34;&gt;&lt;a href=&#34;#cb4-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;group_by&lt;/span&gt;(m) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-8&#34;&gt;&lt;a href=&#34;#cb4-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;nest&lt;/span&gt;() &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-9&#34;&gt;&lt;a href=&#34;#cb4-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb4-10&#34;&gt;&lt;a href=&#34;#cb4-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 2,000 x 2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-11&#34;&gt;&lt;a href=&#34;#cb4-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # Groups:   m [2,000]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-12&#34;&gt;&lt;a href=&#34;#cb4-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##        m data              &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-13&#34;&gt;&lt;a href=&#34;#cb4-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;            &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-14&#34;&gt;&lt;a href=&#34;#cb4-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1     1 &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-15&#34;&gt;&lt;a href=&#34;#cb4-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2     2 &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-16&#34;&gt;&lt;a href=&#34;#cb4-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3     3 &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-17&#34;&gt;&lt;a href=&#34;#cb4-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4     4 &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-18&#34;&gt;&lt;a href=&#34;#cb4-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5     5 &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-19&#34;&gt;&lt;a href=&#34;#cb4-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6     6 &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-20&#34;&gt;&lt;a href=&#34;#cb4-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7     7 &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-21&#34;&gt;&lt;a href=&#34;#cb4-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8     8 &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-22&#34;&gt;&lt;a href=&#34;#cb4-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9     9 &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-23&#34;&gt;&lt;a href=&#34;#cb4-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10    10 &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-24&#34;&gt;&lt;a href=&#34;#cb4-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 1,990 more rows&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;data&lt;/code&gt; column is a &lt;em&gt;list column&lt;/em&gt;, in this case a list of data frames for each row &lt;code&gt;m&lt;/code&gt; (but it could contain other object types if we wanted). List columns are powerful for large-scale data manipulation because we can apply functions over each element in the list, similar to the way &lt;code&gt;apply()&lt;/code&gt; functions work in base R. In our case, we want to apply a function that permutes the values in the &lt;code&gt;treatment&lt;/code&gt; variable. We map this function over the nested data using &lt;code&gt;purrr::map()&lt;/code&gt;, creating a new list column of data frames.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34;&gt;&lt;/a&gt;perm_table &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;sim_table &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-2&#34;&gt;&lt;a href=&#34;#cb5-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-3&#34;&gt;&lt;a href=&#34;#cb5-3&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;permuted_data =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;map&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-4&#34;&gt;&lt;a href=&#34;#cb5-4&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.x =&lt;/span&gt; data, &lt;/span&gt;
&lt;span id=&#34;cb5-5&#34;&gt;&lt;a href=&#34;#cb5-5&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.f =&lt;/span&gt; mutate, &lt;/span&gt;
&lt;span id=&#34;cb5-6&#34;&gt;&lt;a href=&#34;#cb5-6&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;treatment =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;sample&lt;/span&gt;(treatment)&lt;/span&gt;
&lt;span id=&#34;cb5-7&#34;&gt;&lt;a href=&#34;#cb5-7&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb5-8&#34;&gt;&lt;a href=&#34;#cb5-8&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-9&#34;&gt;&lt;a href=&#34;#cb5-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb5-10&#34;&gt;&lt;a href=&#34;#cb5-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 2,000 x 3&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-11&#34;&gt;&lt;a href=&#34;#cb5-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # Groups:   m [2,000]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-12&#34;&gt;&lt;a href=&#34;#cb5-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##        m data               permuted_data     &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-13&#34;&gt;&lt;a href=&#34;#cb5-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;            &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-14&#34;&gt;&lt;a href=&#34;#cb5-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1     1 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-15&#34;&gt;&lt;a href=&#34;#cb5-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2     2 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-16&#34;&gt;&lt;a href=&#34;#cb5-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3     3 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-17&#34;&gt;&lt;a href=&#34;#cb5-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4     4 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-18&#34;&gt;&lt;a href=&#34;#cb5-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5     5 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-19&#34;&gt;&lt;a href=&#34;#cb5-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6     6 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-20&#34;&gt;&lt;a href=&#34;#cb5-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7     7 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-21&#34;&gt;&lt;a href=&#34;#cb5-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8     8 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-22&#34;&gt;&lt;a href=&#34;#cb5-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9     9 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-23&#34;&gt;&lt;a href=&#34;#cb5-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10    10 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-24&#34;&gt;&lt;a href=&#34;#cb5-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 1,990 more rows&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you are new to &lt;code&gt;purrr::map()&lt;/code&gt;, it needs to know two things: a vector or list column &lt;code&gt;.x&lt;/code&gt;, and a function &lt;code&gt;.f&lt;/code&gt; that is applied to each element in &lt;code&gt;.x&lt;/code&gt;. In this case, &lt;code&gt;.x&lt;/code&gt; is a list of data frames, and the function we apply is &lt;code&gt;mutate()&lt;/code&gt;, which creates/modifies variables. We supply the additional function argument saying that we are overwriting the &lt;code&gt;treatment&lt;/code&gt; variable by sampling its current values without replacement. This adds a list-column of 2,000 new data frames, each with a different permutation of treatment assignments. In case you need convincing, here is a table that glimpses the treatment assignments for a subset of &lt;code&gt;m&lt;/code&gt; values.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34;&gt;&lt;/a&gt;perm_table &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-2&#34;&gt;&lt;a href=&#34;#cb6-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;ungroup&lt;/span&gt;() &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-3&#34;&gt;&lt;a href=&#34;#cb6-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;sample_n&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-4&#34;&gt;&lt;a href=&#34;#cb6-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;unnest&lt;/span&gt;(permuted_data) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-5&#34;&gt;&lt;a href=&#34;#cb6-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;select&lt;/span&gt;(m, id, treatment) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-6&#34;&gt;&lt;a href=&#34;#cb6-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;pivot_wider&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-7&#34;&gt;&lt;a href=&#34;#cb6-7&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;names_from =&lt;/span&gt; m, &lt;/span&gt;
&lt;span id=&#34;cb6-8&#34;&gt;&lt;a href=&#34;#cb6-8&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;values_from =&lt;/span&gt; treatment,&lt;/span&gt;
&lt;span id=&#34;cb6-9&#34;&gt;&lt;a href=&#34;#cb6-9&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;names_prefix =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;trt, m = &amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-10&#34;&gt;&lt;a href=&#34;#cb6-10&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb6-11&#34;&gt;&lt;a href=&#34;#cb6-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 500 x 6&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-12&#34;&gt;&lt;a href=&#34;#cb6-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##       id `trt, m = 561` `trt, m = 1471` `trt, m = 1325` `trt, m = 844`&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-13&#34;&gt;&lt;a href=&#34;#cb6-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    &amp;lt;int&amp;gt;          &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;          &amp;lt;dbl&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-14&#34;&gt;&lt;a href=&#34;#cb6-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1     1              0               0               0              1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-15&#34;&gt;&lt;a href=&#34;#cb6-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2     2              0               1               1              0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-16&#34;&gt;&lt;a href=&#34;#cb6-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3     3              1               0               1              1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-17&#34;&gt;&lt;a href=&#34;#cb6-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4     4              0               1               1              1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-18&#34;&gt;&lt;a href=&#34;#cb6-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5     5              1               0               1              1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-19&#34;&gt;&lt;a href=&#34;#cb6-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6     6              0               0               1              0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-20&#34;&gt;&lt;a href=&#34;#cb6-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7     7              0               0               1              1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-21&#34;&gt;&lt;a href=&#34;#cb6-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8     8              1               0               1              1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-22&#34;&gt;&lt;a href=&#34;#cb6-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9     9              1               1               0              1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-23&#34;&gt;&lt;a href=&#34;#cb6-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10    10              0               0               1              1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-24&#34;&gt;&lt;a href=&#34;#cb6-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 490 more rows, and 1 more variable: `trt, m = 943` &amp;lt;dbl&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now that we have datasets with permuted treatments, we calculate some test statistic in each iteration. I will calculate the difference between the treatment and control means, but other statistics are possible as well.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;
We again do this with &lt;code&gt;map()&lt;/code&gt;, this time applying the &lt;code&gt;summarize()&lt;/code&gt; function to calculate the treatment mean, the control mean, and the difference.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34;&gt;&lt;/a&gt;est_table &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;perm_table &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-2&#34;&gt;&lt;a href=&#34;#cb7-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb7-3&#34;&gt;&lt;a href=&#34;#cb7-3&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;estimates =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;map&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb7-4&#34;&gt;&lt;a href=&#34;#cb7-4&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.x =&lt;/span&gt; permuted_data,&lt;/span&gt;
&lt;span id=&#34;cb7-5&#34;&gt;&lt;a href=&#34;#cb7-5&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.f =&lt;/span&gt; summarize, &lt;/span&gt;
&lt;span id=&#34;cb7-6&#34;&gt;&lt;a href=&#34;#cb7-6&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;mean_treatment_m =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;mean&lt;/span&gt;(y[treatment &lt;span class=&#34;op&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]),&lt;/span&gt;
&lt;span id=&#34;cb7-7&#34;&gt;&lt;a href=&#34;#cb7-7&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;mean_control_m =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;mean&lt;/span&gt;(y[treatment &lt;span class=&#34;op&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;]),&lt;/span&gt;
&lt;span id=&#34;cb7-8&#34;&gt;&lt;a href=&#34;#cb7-8&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;diff_means_m =&lt;/span&gt; mean_treatment_m &lt;span class=&#34;op&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;mean_control_m&lt;/span&gt;
&lt;span id=&#34;cb7-9&#34;&gt;&lt;a href=&#34;#cb7-9&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb7-10&#34;&gt;&lt;a href=&#34;#cb7-10&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-11&#34;&gt;&lt;a href=&#34;#cb7-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb7-12&#34;&gt;&lt;a href=&#34;#cb7-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 2,000 x 4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-13&#34;&gt;&lt;a href=&#34;#cb7-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # Groups:   m [2,000]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-14&#34;&gt;&lt;a href=&#34;#cb7-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##        m data               permuted_data      estimates       &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-15&#34;&gt;&lt;a href=&#34;#cb7-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;          &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-16&#34;&gt;&lt;a href=&#34;#cb7-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1     1 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-17&#34;&gt;&lt;a href=&#34;#cb7-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2     2 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-18&#34;&gt;&lt;a href=&#34;#cb7-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3     3 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-19&#34;&gt;&lt;a href=&#34;#cb7-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4     4 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-20&#34;&gt;&lt;a href=&#34;#cb7-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5     5 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-21&#34;&gt;&lt;a href=&#34;#cb7-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6     6 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-22&#34;&gt;&lt;a href=&#34;#cb7-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7     7 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-23&#34;&gt;&lt;a href=&#34;#cb7-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8     8 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-24&#34;&gt;&lt;a href=&#34;#cb7-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9     9 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-25&#34;&gt;&lt;a href=&#34;#cb7-25&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10    10 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-26&#34;&gt;&lt;a href=&#34;#cb7-26&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 1,990 more rows&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can view the estimates in each iteration by unnesting the &lt;code&gt;estimates&lt;/code&gt; column…&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb8&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb8-1&#34;&gt;&lt;a href=&#34;#cb8-1&#34;&gt;&lt;/a&gt;est_summary &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;est_table &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-2&#34;&gt;&lt;a href=&#34;#cb8-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;select&lt;/span&gt;(m, estimates) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-3&#34;&gt;&lt;a href=&#34;#cb8-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;unnest&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;cols =&lt;/span&gt; estimates) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-4&#34;&gt;&lt;a href=&#34;#cb8-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;ungroup&lt;/span&gt;() &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-5&#34;&gt;&lt;a href=&#34;#cb8-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb8-6&#34;&gt;&lt;a href=&#34;#cb8-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 2,000 x 4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-7&#34;&gt;&lt;a href=&#34;#cb8-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##        m mean_treatment_m mean_control_m diff_means_m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-8&#34;&gt;&lt;a href=&#34;#cb8-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    &amp;lt;int&amp;gt;            &amp;lt;dbl&amp;gt;          &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-9&#34;&gt;&lt;a href=&#34;#cb8-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1     1            0.563          0.514      0.0495 &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-10&#34;&gt;&lt;a href=&#34;#cb8-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2     2            0.539          0.537      0.00152&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-11&#34;&gt;&lt;a href=&#34;#cb8-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3     3            0.563          0.514      0.0495 &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-12&#34;&gt;&lt;a href=&#34;#cb8-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4     4            0.535          0.541     -0.00648&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-13&#34;&gt;&lt;a href=&#34;#cb8-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5     5            0.551          0.525      0.0255 &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-14&#34;&gt;&lt;a href=&#34;#cb8-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6     6            0.567          0.510      0.0575 &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-15&#34;&gt;&lt;a href=&#34;#cb8-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7     7            0.490          0.584     -0.0945 &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-16&#34;&gt;&lt;a href=&#34;#cb8-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8     8            0.535          0.541     -0.00648&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-17&#34;&gt;&lt;a href=&#34;#cb8-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9     9            0.518          0.557     -0.0385 &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-18&#34;&gt;&lt;a href=&#34;#cb8-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10    10            0.588          0.490      0.0976 &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-19&#34;&gt;&lt;a href=&#34;#cb8-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 1,990 more rows&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can calculate our &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value by comparing our sample estimate to the null distribution…&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb9&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb9-1&#34;&gt;&lt;a href=&#34;#cb9-1&#34;&gt;&lt;/a&gt;pval &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;est_summary &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb9-2&#34;&gt;&lt;a href=&#34;#cb9-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;summarize&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb9-3&#34;&gt;&lt;a href=&#34;#cb9-3&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;p.value =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;mean&lt;/span&gt;(&lt;span class=&#34;kw&#34;&gt;abs&lt;/span&gt;(diff_means_m) &lt;span class=&#34;op&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;abs&lt;/span&gt;(observed_estimates&lt;span class=&#34;op&#34;&gt;$&lt;/span&gt;diff_means))&lt;/span&gt;
&lt;span id=&#34;cb9-4&#34;&gt;&lt;a href=&#34;#cb9-4&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb9-5&#34;&gt;&lt;a href=&#34;#cb9-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;pull&lt;/span&gt;(p.value) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb9-6&#34;&gt;&lt;a href=&#34;#cb9-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb9-7&#34;&gt;&lt;a href=&#34;#cb9-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## [1] 0.2515&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and we can plot our estimate against the null distribution. In our case, 25% of estimates from the null distribution exceed our in-sample estimate in magnitude, so we would not reject a null hypothesis in this setting.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-22_randomization-inference-purrr_files/figure-html/compare-null-1.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;putting-it-all-together&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Putting it all together&lt;/h2&gt;
&lt;p&gt;In practice, we would not tediously create lots of objects to trace our method every step of the way. Instead, we could build our nested data frame, permute the treatment assignments, and estimate null treatment effects in one continuous operation.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb10&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb10-1&#34;&gt;&lt;a href=&#34;#cb10-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# nested data, permute, estimate.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-2&#34;&gt;&lt;a href=&#34;#cb10-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# bonus: permuted_data demos the &amp;quot;quosure-style lambda function&amp;quot; syntax &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-3&#34;&gt;&lt;a href=&#34;#cb10-3&#34;&gt;&lt;/a&gt;ri_data &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;d &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-4&#34;&gt;&lt;a href=&#34;#cb10-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;crossing&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;m =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;:&lt;/span&gt;n_sims) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-5&#34;&gt;&lt;a href=&#34;#cb10-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;group_by&lt;/span&gt;(m) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-6&#34;&gt;&lt;a href=&#34;#cb10-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;nest&lt;/span&gt;() &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-7&#34;&gt;&lt;a href=&#34;#cb10-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb10-8&#34;&gt;&lt;a href=&#34;#cb10-8&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;permuted_data =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;map&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb10-9&#34;&gt;&lt;a href=&#34;#cb10-9&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.x =&lt;/span&gt; data, &lt;/span&gt;
&lt;span id=&#34;cb10-10&#34;&gt;&lt;a href=&#34;#cb10-10&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.f =&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;~&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(.x, &lt;span class=&#34;dt&#34;&gt;treatment =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;sample&lt;/span&gt;(treatment))&lt;/span&gt;
&lt;span id=&#34;cb10-11&#34;&gt;&lt;a href=&#34;#cb10-11&#34;&gt;&lt;/a&gt;    ),&lt;/span&gt;
&lt;span id=&#34;cb10-12&#34;&gt;&lt;a href=&#34;#cb10-12&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;estimates =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;map&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb10-13&#34;&gt;&lt;a href=&#34;#cb10-13&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.x =&lt;/span&gt; permuted_data,&lt;/span&gt;
&lt;span id=&#34;cb10-14&#34;&gt;&lt;a href=&#34;#cb10-14&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.f =&lt;/span&gt; summarize,&lt;/span&gt;
&lt;span id=&#34;cb10-15&#34;&gt;&lt;a href=&#34;#cb10-15&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;mean_treatment_m =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;mean&lt;/span&gt;(y[treatment &lt;span class=&#34;op&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]),&lt;/span&gt;
&lt;span id=&#34;cb10-16&#34;&gt;&lt;a href=&#34;#cb10-16&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;mean_control_m =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;mean&lt;/span&gt;(y[treatment &lt;span class=&#34;op&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;]),&lt;/span&gt;
&lt;span id=&#34;cb10-17&#34;&gt;&lt;a href=&#34;#cb10-17&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;diff_means_m =&lt;/span&gt; mean_treatment_m &lt;span class=&#34;op&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;mean_control_m&lt;/span&gt;
&lt;span id=&#34;cb10-18&#34;&gt;&lt;a href=&#34;#cb10-18&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb10-19&#34;&gt;&lt;a href=&#34;#cb10-19&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-20&#34;&gt;&lt;a href=&#34;#cb10-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb10-21&#34;&gt;&lt;a href=&#34;#cb10-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 2,000 x 4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-22&#34;&gt;&lt;a href=&#34;#cb10-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # Groups:   m [2,000]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-23&#34;&gt;&lt;a href=&#34;#cb10-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##        m data               permuted_data      estimates       &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-24&#34;&gt;&lt;a href=&#34;#cb10-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;          &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-25&#34;&gt;&lt;a href=&#34;#cb10-25&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1     1 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-26&#34;&gt;&lt;a href=&#34;#cb10-26&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2     2 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-27&#34;&gt;&lt;a href=&#34;#cb10-27&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3     3 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-28&#34;&gt;&lt;a href=&#34;#cb10-28&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4     4 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-29&#34;&gt;&lt;a href=&#34;#cb10-29&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5     5 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-30&#34;&gt;&lt;a href=&#34;#cb10-30&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6     6 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-31&#34;&gt;&lt;a href=&#34;#cb10-31&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7     7 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-32&#34;&gt;&lt;a href=&#34;#cb10-32&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8     8 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-33&#34;&gt;&lt;a href=&#34;#cb10-33&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9     9 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-34&#34;&gt;&lt;a href=&#34;#cb10-34&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10    10 &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [500 × 3]&amp;gt; &amp;lt;tibble [1 × 3]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-35&#34;&gt;&lt;a href=&#34;#cb10-35&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 1,990 more rows&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;extensibility-of-the-tidy-approach&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Extensibility of the Tidy Approach&lt;/h1&gt;
&lt;p&gt;We’ve seen that using &lt;code&gt;purrr::map()&lt;/code&gt; lets us push around a &lt;em&gt;lot&lt;/em&gt; of data with little code. Yet the &lt;code&gt;purrr&lt;/code&gt; approach is still more verbose than other approaches that we might have used (see Thomas Leeper’s use of &lt;code&gt;replicate()&lt;/code&gt; and &lt;code&gt;by()&lt;/code&gt; &lt;a href=&#34;https://thomasleeper.com/Rcourse/Tutorials/permutationtests.html&#34;&gt;here&lt;/a&gt;). Why would we use the tidy approach if slimmer methods exist? For one, it is eminently extensible. By keeping the fruits of your work together in one data frame, it is easy to adapt the workflow to incorporate other quantities of interest and research design features while keeping your work organized. This section will take a quick tour of how easy it is to (1) calculate confidence intervals and permute data from (2) multiple treatments, (3) cluster randomization, and (4) block-randomization.&lt;/p&gt;
&lt;div id=&#34;confidence-intervals&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Confidence Intervals&lt;/h3&gt;
&lt;p&gt;So far we have entertained a generative model where (1) treatment has a constant, additive effect &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; on unit-level response and (2) a null hypothesis that &lt;span class=&#34;math inline&#34;&gt;\(\delta = 0\)&lt;/span&gt;.&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;
If we entertain null hypothesis values for &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; other than strictly zero, we can construct a &lt;span class=&#34;math inline&#34;&gt;\(100 - \alpha\)&lt;/span&gt; confidence region as &lt;em&gt;the values of &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; for which we cannot reject the null hypothesis&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We do this as follows. For a null value of &lt;span class=&#34;math inline&#34;&gt;\(\delta_{0}\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adjust the in-sample test statistic by subtracting &lt;span class=&#34;math inline&#34;&gt;\(\delta_{0}\)&lt;/span&gt; from the difference in means. This is similar to the way we would subtract the null value from a standard &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-test &lt;span class=&#34;math inline&#34;&gt;\(\left(\frac{\hat{\mu} - \mu_{0}}{\sigma}\right)\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Calculate the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; value for this adjusted &lt;span class=&#34;math inline&#34;&gt;\(\hat{\delta}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; \frac{\alpha}{2}\)&lt;/span&gt;, we reject the null hypothesis that &lt;span class=&#34;math inline&#34;&gt;\(\delta = \delta_0\)&lt;/span&gt;, meaning the value &lt;span class=&#34;math inline&#34;&gt;\(\delta_{0}\)&lt;/span&gt; is &lt;em&gt;not&lt;/em&gt; contained in the confidence interval.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can implement this routine by augmenting our data structure with a sequence of null values and performing the appropriate adjustments.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb11&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb11-1&#34;&gt;&lt;a href=&#34;#cb11-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# for each m x delta_0, adjust the test statistic&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-2&#34;&gt;&lt;a href=&#34;#cb11-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# for each delta_0, calculate p-value &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-3&#34;&gt;&lt;a href=&#34;#cb11-3&#34;&gt;&lt;/a&gt;conf_table &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;ri_data &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-4&#34;&gt;&lt;a href=&#34;#cb11-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;select&lt;/span&gt;(m, estimates) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-5&#34;&gt;&lt;a href=&#34;#cb11-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;unnest&lt;/span&gt;(estimates) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-6&#34;&gt;&lt;a href=&#34;#cb11-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;crossing&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;null_value =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;op&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;.01&lt;/span&gt;)) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-7&#34;&gt;&lt;a href=&#34;#cb11-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;test_value =&lt;/span&gt; observed_estimates&lt;span class=&#34;op&#34;&gt;$&lt;/span&gt;diff_means &lt;span class=&#34;op&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;null_value) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-8&#34;&gt;&lt;a href=&#34;#cb11-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;group_by&lt;/span&gt;(null_value) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-9&#34;&gt;&lt;a href=&#34;#cb11-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;summarize&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb11-10&#34;&gt;&lt;a href=&#34;#cb11-10&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;p.value =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;mean&lt;/span&gt;(diff_means_m &lt;span class=&#34;op&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;abs&lt;/span&gt;(test_value))&lt;/span&gt;
&lt;span id=&#34;cb11-11&#34;&gt;&lt;a href=&#34;#cb11-11&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-12&#34;&gt;&lt;a href=&#34;#cb11-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb11-13&#34;&gt;&lt;a href=&#34;#cb11-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 41 x 2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-14&#34;&gt;&lt;a href=&#34;#cb11-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    null_value p.value&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-15&#34;&gt;&lt;a href=&#34;#cb11-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##         &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-16&#34;&gt;&lt;a href=&#34;#cb11-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1      -0.2        0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-17&#34;&gt;&lt;a href=&#34;#cb11-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2      -0.19       0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-18&#34;&gt;&lt;a href=&#34;#cb11-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3      -0.18       0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-19&#34;&gt;&lt;a href=&#34;#cb11-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4      -0.17       0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-20&#34;&gt;&lt;a href=&#34;#cb11-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5      -0.16       0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-21&#34;&gt;&lt;a href=&#34;#cb11-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6      -0.15       0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-22&#34;&gt;&lt;a href=&#34;#cb11-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7      -0.14       0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-23&#34;&gt;&lt;a href=&#34;#cb11-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8      -0.13       0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-24&#34;&gt;&lt;a href=&#34;#cb11-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9      -0.12       0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-25&#34;&gt;&lt;a href=&#34;#cb11-25&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10      -0.11       0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-26&#34;&gt;&lt;a href=&#34;#cb11-26&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 31 more rows&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We saw above that our point estimate for the difference in means is roughly 0.05, but now that we found the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value under this sequence of hypothesis tests, we know the null values of &lt;span class=&#34;math inline&#34;&gt;\(\delta_0\)&lt;/span&gt; that cannot be rejected, giving us a 93% interval [-0.04, 0.13] inclusive.&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;
Below I plot the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value at each null &lt;span class=&#34;math inline&#34;&gt;\(\delta_{0}\)&lt;/span&gt; as bars. Bars are colored red if they represent values of &lt;span class=&#34;math inline&#34;&gt;\(\delta_{0}\)&lt;/span&gt; that can be rejected at &lt;span class=&#34;math inline&#34;&gt;\(\alpha = .05\)&lt;/span&gt;. What remains is the values that cannot be rejected, which I use to draw the confidence interval below the bars. It’s important to remember that this is not a plot of a posterior distribution, so the height of the bar does not indicate the plausibility or credibility of a given &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; value.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-22_randomization-inference-purrr_files/figure-html/plot-conf-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-treatments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiple treatments&lt;/h2&gt;
&lt;p&gt;Suppose that we had outcome data that were a function of multiple treatment conditions. Here is some fake data from an experiment where subjects rate potential candidates on a 0-10 scale, where the researcher manipulates the candidates party affiliation, occupation, and issue stances.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 500 x 7
##       id cand_rating party occupation issue_tax issue_abortion issue_environment
##    &amp;lt;int&amp;gt;       &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;int&amp;gt;     &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;             &amp;lt;int&amp;gt;
##  1     1           9     1          4         3              2                 3
##  2     2           2     2          2         1              3                 3
##  3     3           2     2          4         2              4                 1
##  4     4           7     2          3         2              3                 3
##  5     5           2     1          4         2              3                 1
##  6     6           5     2          2         1              2                 2
##  7     7           2     2          1         3              4                 3
##  8     8           8     2          3         3              2                 3
##  9     9          10     1          4         3              3                 2
## 10    10           6     1          2         2              1                 2
## # … with 490 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is easy to permute the values of multiple variables at once. The only thing that changes from the above workflow is that we map &lt;code&gt;mutate_at()&lt;/code&gt; to each iteration, specifying that we want to sample the values of an arbitrary set of treatment variables. Supposing that this data were called &lt;code&gt;multi_treat&lt;/code&gt;…&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb13&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb13-1&#34;&gt;&lt;a href=&#34;#cb13-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-2&#34;&gt;&lt;a href=&#34;#cb13-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# helpful but not necessary:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-3&#34;&gt;&lt;a href=&#34;#cb13-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# save a vector of treatment names for easy access&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-4&#34;&gt;&lt;a href=&#34;#cb13-4&#34;&gt;&lt;/a&gt;treatments &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-5&#34;&gt;&lt;a href=&#34;#cb13-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&amp;quot;party&amp;quot;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&amp;quot;occupation&amp;quot;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&amp;quot;issue_tax&amp;quot;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&amp;quot;issue_abortion&amp;quot;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&amp;quot;issue_environment&amp;quot;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb13-6&#34;&gt;&lt;a href=&#34;#cb13-6&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-7&#34;&gt;&lt;a href=&#34;#cb13-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# resample values for each var in `treatments`&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-8&#34;&gt;&lt;a href=&#34;#cb13-8&#34;&gt;&lt;/a&gt;multi_permuted &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;multi_treat &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-9&#34;&gt;&lt;a href=&#34;#cb13-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;crossing&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;m =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;1000&lt;/span&gt;) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-10&#34;&gt;&lt;a href=&#34;#cb13-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;group_by&lt;/span&gt;(m) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-11&#34;&gt;&lt;a href=&#34;#cb13-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;nest&lt;/span&gt;() &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-12&#34;&gt;&lt;a href=&#34;#cb13-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-13&#34;&gt;&lt;a href=&#34;#cb13-13&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;permuted_data =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;map&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-14&#34;&gt;&lt;a href=&#34;#cb13-14&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.x =&lt;/span&gt; data, &lt;/span&gt;
&lt;span id=&#34;cb13-15&#34;&gt;&lt;a href=&#34;#cb13-15&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.f =&lt;/span&gt; mutate_at,&lt;/span&gt;
&lt;span id=&#34;cb13-16&#34;&gt;&lt;a href=&#34;#cb13-16&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.vars =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;vars&lt;/span&gt;(&lt;span class=&#34;kw&#34;&gt;one_of&lt;/span&gt;(treatments)),&lt;/span&gt;
&lt;span id=&#34;cb13-17&#34;&gt;&lt;a href=&#34;#cb13-17&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.funs =&lt;/span&gt; sample&lt;/span&gt;
&lt;span id=&#34;cb13-18&#34;&gt;&lt;a href=&#34;#cb13-18&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb13-19&#34;&gt;&lt;a href=&#34;#cb13-19&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-20&#34;&gt;&lt;a href=&#34;#cb13-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb13-21&#34;&gt;&lt;a href=&#34;#cb13-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 1,000 x 3&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-22&#34;&gt;&lt;a href=&#34;#cb13-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # Groups:   m [1,000]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-23&#34;&gt;&lt;a href=&#34;#cb13-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##        m data               permuted_data     &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-24&#34;&gt;&lt;a href=&#34;#cb13-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;            &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-25&#34;&gt;&lt;a href=&#34;#cb13-25&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1     1 &amp;lt;tibble [500 × 7]&amp;gt; &amp;lt;tibble [500 × 7]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-26&#34;&gt;&lt;a href=&#34;#cb13-26&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2     2 &amp;lt;tibble [500 × 7]&amp;gt; &amp;lt;tibble [500 × 7]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-27&#34;&gt;&lt;a href=&#34;#cb13-27&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3     3 &amp;lt;tibble [500 × 7]&amp;gt; &amp;lt;tibble [500 × 7]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-28&#34;&gt;&lt;a href=&#34;#cb13-28&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4     4 &amp;lt;tibble [500 × 7]&amp;gt; &amp;lt;tibble [500 × 7]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-29&#34;&gt;&lt;a href=&#34;#cb13-29&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5     5 &amp;lt;tibble [500 × 7]&amp;gt; &amp;lt;tibble [500 × 7]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-30&#34;&gt;&lt;a href=&#34;#cb13-30&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6     6 &amp;lt;tibble [500 × 7]&amp;gt; &amp;lt;tibble [500 × 7]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-31&#34;&gt;&lt;a href=&#34;#cb13-31&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7     7 &amp;lt;tibble [500 × 7]&amp;gt; &amp;lt;tibble [500 × 7]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-32&#34;&gt;&lt;a href=&#34;#cb13-32&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8     8 &amp;lt;tibble [500 × 7]&amp;gt; &amp;lt;tibble [500 × 7]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-33&#34;&gt;&lt;a href=&#34;#cb13-33&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9     9 &amp;lt;tibble [500 × 7]&amp;gt; &amp;lt;tibble [500 × 7]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-34&#34;&gt;&lt;a href=&#34;#cb13-34&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10    10 &amp;lt;tibble [500 × 7]&amp;gt; &amp;lt;tibble [500 × 7]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-35&#34;&gt;&lt;a href=&#34;#cb13-35&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 990 more rows&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You would then be able to &lt;code&gt;map()&lt;/code&gt; whatever estimation model you wanted over the &lt;code&gt;permuted_data&lt;/code&gt; column, thereby estimating the model in each group &lt;code&gt;m&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;block-randomization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Block Randomization&lt;/h2&gt;
&lt;p&gt;Suppose we had data that were randomized within blocks. The data below contain &lt;span class=&#34;math inline&#34;&gt;\(n = 500\)&lt;/span&gt; observations and 5 blocks, with each block containing 50 treated units and 50 control units.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 500 x 4
##       id block treatment     y
##    &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1     1     2         1     0
##  2     2     3         0     1
##  3     3     4         0     0
##  4     4     5         1     1
##  5     5     1         0     0
##  6     6     2         0     1
##  7     7     3         1     1
##  8     8     4         1     0
##  9     9     5         1     0
## 10    10     1         1     1
## # … with 490 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can’t naively permute the treatments over the whole data, since we want to respect the blocking structure. To permute treatments within blocks, we only require one additional step, which is to group the data by block during the permutation step.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb15&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb15-1&#34;&gt;&lt;a href=&#34;#cb15-1&#34;&gt;&lt;/a&gt;block_data &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-2&#34;&gt;&lt;a href=&#34;#cb15-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;crossing&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;m =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;1000&lt;/span&gt;) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-3&#34;&gt;&lt;a href=&#34;#cb15-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;group_by&lt;/span&gt;(m) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-4&#34;&gt;&lt;a href=&#34;#cb15-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;nest&lt;/span&gt;() &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-5&#34;&gt;&lt;a href=&#34;#cb15-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb15-6&#34;&gt;&lt;a href=&#34;#cb15-6&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;permuted_data =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;map&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb15-7&#34;&gt;&lt;a href=&#34;#cb15-7&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.x =&lt;/span&gt; data, &lt;/span&gt;
&lt;span id=&#34;cb15-8&#34;&gt;&lt;a href=&#34;#cb15-8&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.f =&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;~&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;.x &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-9&#34;&gt;&lt;a href=&#34;#cb15-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;group_by&lt;/span&gt;(block) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-10&#34;&gt;&lt;a href=&#34;#cb15-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;treatment =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;sample&lt;/span&gt;(treatment)) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-11&#34;&gt;&lt;a href=&#34;#cb15-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;ungroup&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb15-12&#34;&gt;&lt;a href=&#34;#cb15-12&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb15-13&#34;&gt;&lt;a href=&#34;#cb15-13&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-14&#34;&gt;&lt;a href=&#34;#cb15-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb15-15&#34;&gt;&lt;a href=&#34;#cb15-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 1,000 x 3&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-16&#34;&gt;&lt;a href=&#34;#cb15-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # Groups:   m [1,000]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-17&#34;&gt;&lt;a href=&#34;#cb15-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##        m data               permuted_data     &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-18&#34;&gt;&lt;a href=&#34;#cb15-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;            &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-19&#34;&gt;&lt;a href=&#34;#cb15-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1     1 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-20&#34;&gt;&lt;a href=&#34;#cb15-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2     2 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-21&#34;&gt;&lt;a href=&#34;#cb15-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3     3 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-22&#34;&gt;&lt;a href=&#34;#cb15-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4     4 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-23&#34;&gt;&lt;a href=&#34;#cb15-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5     5 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-24&#34;&gt;&lt;a href=&#34;#cb15-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6     6 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-25&#34;&gt;&lt;a href=&#34;#cb15-25&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7     7 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-26&#34;&gt;&lt;a href=&#34;#cb15-26&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8     8 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-27&#34;&gt;&lt;a href=&#34;#cb15-27&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9     9 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-28&#34;&gt;&lt;a href=&#34;#cb15-28&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10    10 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-29&#34;&gt;&lt;a href=&#34;#cb15-29&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 990 more rows&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;cluster-randomization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cluster randomization&lt;/h2&gt;
&lt;p&gt;With cluster-randomized data, units are grouped within a cluster, and then every unit within a cluster gets the same treatment. Cluster-randomized data might look like so:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 500 x 4
##       id cluster treatment     y
##    &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1     1       1         0     1
##  2     2       1         0     0
##  3     3       1         0     0
##  4     4       1         0     1
##  5     5       1         0     0
##  6     6       2         1     1
##  7     7       2         1     0
##  8     8       2         1     1
##  9     9       2         1     1
## 10    10       2         1     0
## # … with 490 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to permute the treatment assignments, we have to reshuffle the treatment status for each cluster such that all units in the same cluster get the same treatment. This is possible, but it’s a bit abstract, since it requires a nest-within-a-nest (whoa…). When we &lt;code&gt;map()&lt;/code&gt; the function to permute the data, we do the following within each iteration &lt;code&gt;m&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nest the unit-level variables (&lt;code&gt;id&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;) into a list-column. What remains is a data frame that is one row per cluster.&lt;/li&gt;
&lt;li&gt;Permute the treatment assignments at the cluster level&lt;/li&gt;
&lt;li&gt;Unnest the unit-level data, at which point every unit inherits its cluster-level treatment assignment.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb17&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb17-1&#34;&gt;&lt;a href=&#34;#cb17-1&#34;&gt;&lt;/a&gt;cluster_permuted &amp;lt;-&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;cluster_data &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-2&#34;&gt;&lt;a href=&#34;#cb17-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;crossing&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;m =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;1000&lt;/span&gt;) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-3&#34;&gt;&lt;a href=&#34;#cb17-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;group_by&lt;/span&gt;(m) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-4&#34;&gt;&lt;a href=&#34;#cb17-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;nest&lt;/span&gt;() &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-5&#34;&gt;&lt;a href=&#34;#cb17-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb17-6&#34;&gt;&lt;a href=&#34;#cb17-6&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;dt&#34;&gt;permuted_data =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;map&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb17-7&#34;&gt;&lt;a href=&#34;#cb17-7&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.x =&lt;/span&gt; data,&lt;/span&gt;
&lt;span id=&#34;cb17-8&#34;&gt;&lt;a href=&#34;#cb17-8&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;dt&#34;&gt;.f =&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;~&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &lt;/span&gt;.x &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-9&#34;&gt;&lt;a href=&#34;#cb17-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;nest&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;within_cluster =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;c&lt;/span&gt;(id, y)) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-10&#34;&gt;&lt;a href=&#34;#cb17-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;dt&#34;&gt;treatment =&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;sample&lt;/span&gt;(treatment)) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-11&#34;&gt;&lt;a href=&#34;#cb17-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;unnest&lt;/span&gt;(within_cluster)&lt;/span&gt;
&lt;span id=&#34;cb17-12&#34;&gt;&lt;a href=&#34;#cb17-12&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb17-13&#34;&gt;&lt;a href=&#34;#cb17-13&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;op&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-14&#34;&gt;&lt;a href=&#34;#cb17-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;st&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;print&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb17-15&#34;&gt;&lt;a href=&#34;#cb17-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # A tibble: 1,000 x 3&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-16&#34;&gt;&lt;a href=&#34;#cb17-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # Groups:   m [1,000]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-17&#34;&gt;&lt;a href=&#34;#cb17-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##        m data               permuted_data     &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-18&#34;&gt;&lt;a href=&#34;#cb17-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;            &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-19&#34;&gt;&lt;a href=&#34;#cb17-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  1     1 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-20&#34;&gt;&lt;a href=&#34;#cb17-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  2     2 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-21&#34;&gt;&lt;a href=&#34;#cb17-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  3     3 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-22&#34;&gt;&lt;a href=&#34;#cb17-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  4     4 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-23&#34;&gt;&lt;a href=&#34;#cb17-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  5     5 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-24&#34;&gt;&lt;a href=&#34;#cb17-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  6     6 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-25&#34;&gt;&lt;a href=&#34;#cb17-25&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  7     7 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-26&#34;&gt;&lt;a href=&#34;#cb17-26&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  8     8 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-27&#34;&gt;&lt;a href=&#34;#cb17-27&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;##  9     9 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-28&#34;&gt;&lt;a href=&#34;#cb17-28&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## 10    10 &amp;lt;tibble [500 × 4]&amp;gt; &amp;lt;tibble [500 × 4]&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-29&#34;&gt;&lt;a href=&#34;#cb17-29&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;## # … with 990 more rows&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To assure you that this works, I will plot the treatment status of all units within 3 clusters across the first 10 permutations. We should see that all units in the same cluster share the same treatment status within the same treatment permutation &lt;code&gt;m&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-22_randomization-inference-purrr_files/figure-html/plot-unit-clusters-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;
I’ll shout out &lt;a href=&#34;https://cran.r-project.org/web/packages/ri2/&#34;&gt;ri2&lt;/a&gt; in particular.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;
The paper by &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-5907.2011.00576.x?casa_token=YjkCBZcxieAAAAAA:-WVWyv9NfA_83dsFCKLYjofLTVBEKehe0cG3a3na-7OQhSQrURDVGsjgeKwHSv6KI5jrXpmNV5Bog9A&#34;&gt;Keele, McConnaughy, and White&lt;/a&gt; discusses and includes examples of other statistics such as rank-based tests, encouraging researchers to consider theory and the assumptions they are willing to make about the data, such as the choice of a “sharp” null hypothesis.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;
The estimated treatment effect is actually very close to the true effect, so what we’re seeing is a low-powered study.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;
This arguably requires more (or at least “different”) assumptions compared to a pure “Fisherian” approach to randomization inference, which is possible under a sharp null hypothesis that &lt;em&gt;treatment has zero effect for all units&lt;/em&gt;.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;
Due to the discrete nature of the &lt;span class=&#34;math inline&#34;&gt;\(\delta_{0}\)&lt;/span&gt; values, we do not obtain a perfect 95% interval.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Git information in your open-source research paper (with Rmarkdown)
</title>
      <link>/post/git-in-papers/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/git-in-papers/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;style type=&#34;text/css&#34;&gt;
pre &gt; code.sourceCode { white-space: pre; position: relative; }
pre &gt; code.sourceCode &gt; span { display: inline-block; line-height: 1.25; }
pre &gt; code.sourceCode &gt; span:empty { height: 1.2em; }
code.sourceCode &gt; span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre &gt; code.sourceCode { white-space: pre-wrap; }
pre &gt; code.sourceCode &gt; span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code &gt; span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code &gt; span &gt; a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre &gt; code.sourceCode &gt; span &gt; a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
&lt;/style&gt;


&lt;div id=&#34;motivation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;One benefit of open-source research is that it is possible to trace the history of a research product through its (potentially many) iterations using a versioning system such as Git. This is great for readers who encounter the project’s remote repository, but it’s more likely the case that readers will encounter only a PDF of your paper in an email or through a preprint archive. While services like ArXiv will watermark your paper, it (or so it seems) only includes information about the paper’s history in ArXiv specifically, rather its history in your Git repository. This post describes how you can use Rmarkdown to include Git information into a working draft of your research paper.&lt;/p&gt;
&lt;p&gt;What exactly do I mean? Your paper typically includes the date of compilation, but you could also include the current commit hash, the branch of the current commit, and so on. Why would you want to do this?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A compilation system like &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt; can print the date of compilation, but it is often the case that documents are re-compiled without any real changes. This means the compilation date can be a deceiving signal about when the paper was most recently modified. You may want to “timestamp” a version of your paper in a way that is robust to re-compilation at an arbitrary future time.&lt;/li&gt;
&lt;li&gt;As you develop your paper locally, you may commit several small changes between major versions of your paper. To prevent your “in-development” copy from being confused for a major version of the paper, you may want to note which commit generated the current PDF and perhaps link to a more stable “for public eyes” version of the paper elsewhere.&lt;/li&gt;
&lt;li&gt;A more general case of the previous point: suppose you develop your project across multiple branches (e.g. as with &lt;a href=&#34;https://datasift.github.io/gitflow/IntroducingGitFlow.html&#34;&gt;“Git flow”&lt;/a&gt;). You may reserve your “master” branch for major versions of the project while iteratively developing the project (and compiling the document) on a non-master branch. In this case, you might want to know if a PDF was compiled from source code on the master branch (i.e. “Am I looking at a major version of the paper”) or on an in-development branch.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is an example from one of my in-progress papers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/for-posts/git-date.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;This setup prioritizes the commit hash over the compilation date as a method for “dating” your paper. The branch name is included in cases where the PDF is generated on a development branch instead of on the master/public branch. The footnote corresponding to the commit information contains the commit message (not shown). And lastly, the link to the public version takes you to the master branch PDF on Github—the most recent major version.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-do-it&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to do it&lt;/h1&gt;
&lt;p&gt;Setting this up consists of essentially two steps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Learn to print Git commands to the console using R.&lt;/li&gt;
&lt;li&gt;Place that R code in your &lt;code&gt;.Rmd&lt;/code&gt; document’s YAML header.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;console-commands-with-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Console commands with R&lt;/h2&gt;
&lt;p&gt;We can run console commands within R using the &lt;code&gt;system()&lt;/code&gt; function. Ordinarily the results of the commands merely print to the console instead of being treated as objects, but we want to make these objects be accessible in the R environment using the &lt;code&gt;intern = TRUE&lt;/code&gt; argument.&lt;/p&gt;
&lt;p&gt;Here are some examples that will display Git information for my website repo (where this code is currently being evaluated).&lt;/p&gt;
&lt;p&gt;For instance, how can we print the branch name?&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;system&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&amp;quot;git symbolic-ref --short HEAD&amp;quot;&lt;/span&gt;, &lt;span class=&#34;dt&#34;&gt;intern =&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;TRUE&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;master&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To print only the hashes in your Git log, you can supply &lt;code&gt;%t&lt;/code&gt; to the the &lt;code&gt;--pretty&lt;/code&gt; argument of &lt;code&gt;git log&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;system&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&amp;quot;git log --pretty=%t&amp;quot;&lt;/span&gt;, &lt;span class=&#34;dt&#34;&gt;intern =&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;TRUE&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;b8d24f2&amp;quot; &amp;quot;9da4ece&amp;quot; &amp;quot;8cccbf9&amp;quot; &amp;quot;45d0315&amp;quot; &amp;quot;9d26ba5&amp;quot; &amp;quot;6ebb3b0&amp;quot; &amp;quot;af8a617&amp;quot;
##   [8] &amp;quot;2c6ec85&amp;quot; &amp;quot;22fea55&amp;quot; &amp;quot;3854af2&amp;quot; &amp;quot;93d13c4&amp;quot; &amp;quot;b297079&amp;quot; &amp;quot;f8b6836&amp;quot; &amp;quot;d988f5c&amp;quot;
##  [15] &amp;quot;6fc4555&amp;quot; &amp;quot;eabf878&amp;quot; &amp;quot;d6bf55f&amp;quot; &amp;quot;ecc0c17&amp;quot; &amp;quot;322d6d8&amp;quot; &amp;quot;b204b83&amp;quot; &amp;quot;604a055&amp;quot;
##  [22] &amp;quot;5b6cd16&amp;quot; &amp;quot;7f3d4e8&amp;quot; &amp;quot;3e3d9d1&amp;quot; &amp;quot;c5c2a6b&amp;quot; &amp;quot;72ecc5a&amp;quot; &amp;quot;bd25ad7&amp;quot; &amp;quot;2820840&amp;quot;
##  [29] &amp;quot;f8be89c&amp;quot; &amp;quot;5011495&amp;quot; &amp;quot;b4f159a&amp;quot; &amp;quot;471d45e&amp;quot; &amp;quot;32e03b8&amp;quot; &amp;quot;d55b641&amp;quot; &amp;quot;175df3e&amp;quot;
##  [36] &amp;quot;03985bd&amp;quot; &amp;quot;549e2f0&amp;quot; &amp;quot;8effeb6&amp;quot; &amp;quot;e7c1fc3&amp;quot; &amp;quot;19f3bcd&amp;quot; &amp;quot;0647521&amp;quot; &amp;quot;5913357&amp;quot;
##  [43] &amp;quot;b146ac2&amp;quot; &amp;quot;494f860&amp;quot; &amp;quot;557bf2a&amp;quot; &amp;quot;2b367c7&amp;quot; &amp;quot;734e099&amp;quot; &amp;quot;8ef25d4&amp;quot; &amp;quot;1d949ce&amp;quot;
##  [50] &amp;quot;ed14db3&amp;quot; &amp;quot;ba4694c&amp;quot; &amp;quot;57d5fc6&amp;quot; &amp;quot;1656482&amp;quot; &amp;quot;28d68d7&amp;quot; &amp;quot;5b8e92a&amp;quot; &amp;quot;a807aab&amp;quot;
##  [57] &amp;quot;359f06a&amp;quot; &amp;quot;78c3ee3&amp;quot; &amp;quot;defc14f&amp;quot; &amp;quot;ec7e081&amp;quot; &amp;quot;e4c9176&amp;quot; &amp;quot;ab502db&amp;quot; &amp;quot;7fe3ee6&amp;quot;
##  [64] &amp;quot;2f97534&amp;quot; &amp;quot;3259f27&amp;quot; &amp;quot;bec13bd&amp;quot; &amp;quot;f3142cc&amp;quot; &amp;quot;2959bf6&amp;quot; &amp;quot;b4754c2&amp;quot; &amp;quot;91fe96a&amp;quot;
##  [71] &amp;quot;91bba9b&amp;quot; &amp;quot;071d153&amp;quot; &amp;quot;8e4cce3&amp;quot; &amp;quot;ba09b95&amp;quot; &amp;quot;741632b&amp;quot; &amp;quot;3569cdc&amp;quot; &amp;quot;d99c163&amp;quot;
##  [78] &amp;quot;5c135e3&amp;quot; &amp;quot;2671a4b&amp;quot; &amp;quot;2b7d810&amp;quot; &amp;quot;ea7d44d&amp;quot; &amp;quot;6c7656c&amp;quot; &amp;quot;e40d5d8&amp;quot; &amp;quot;bb9199d&amp;quot;
##  [85] &amp;quot;ca4e593&amp;quot; &amp;quot;c42c33f&amp;quot; &amp;quot;d17291e&amp;quot; &amp;quot;38d1910&amp;quot; &amp;quot;6bc2299&amp;quot; &amp;quot;3131d9d&amp;quot; &amp;quot;5906234&amp;quot;
##  [92] &amp;quot;d355f02&amp;quot; &amp;quot;7a6e215&amp;quot; &amp;quot;c5befba&amp;quot; &amp;quot;b0dba1c&amp;quot; &amp;quot;c1d6342&amp;quot; &amp;quot;87f3ceb&amp;quot; &amp;quot;83ca75b&amp;quot;
##  [99] &amp;quot;69e41cf&amp;quot; &amp;quot;f9278c7&amp;quot; &amp;quot;a3ee86e&amp;quot; &amp;quot;816ebb5&amp;quot; &amp;quot;030278d&amp;quot; &amp;quot;2d9384b&amp;quot; &amp;quot;fec8391&amp;quot;
## [106] &amp;quot;83dbb8c&amp;quot; &amp;quot;1210553&amp;quot; &amp;quot;ce35ec0&amp;quot; &amp;quot;ab3c776&amp;quot; &amp;quot;c62ad9f&amp;quot; &amp;quot;3148687&amp;quot; &amp;quot;c3621d8&amp;quot;
## [113] &amp;quot;943687e&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use indexing to isolate only the most recent hash from this vector of results.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;system&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&amp;quot;git log --pretty=%t&amp;quot;&lt;/span&gt;, &lt;span class=&#34;dt&#34;&gt;intern =&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;TRUE&lt;/span&gt;)[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;b8d24f2&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To print the commit message, use &lt;code&gt;--pretty=%s&lt;/code&gt; instead.&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode r&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;system&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&amp;quot;git log --pretty=%s&amp;quot;&lt;/span&gt;, &lt;span class=&#34;dt&#34;&gt;intern =&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;TRUE&lt;/span&gt;)[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;rephrasing things to sound nicer&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;r-results-in-the-yaml&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R results in the YAML&lt;/h2&gt;
&lt;p&gt;Now that we know which commands to run to get the Git info, how do we get this information into our YAML? We will do this using inline R code chunks. This image shows what I’ve done for the above paper example, and I describe a few of the tricks I use below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/for-posts/git-yaml.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We use the &lt;code&gt;date&lt;/code&gt; variable, but we supply multiple lines of content. To do this, place a pipe &lt;code&gt;|&lt;/code&gt; after declaring the &lt;code&gt;date&lt;/code&gt; variable, and begin each line with a new pipe &lt;code&gt;|&lt;/code&gt;. This will line-break the content in your compiled PDF and let you supply &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt; code directly to the variable.&lt;/li&gt;
&lt;li&gt;To use teletype/fixed-width font, type the &lt;code&gt;\texttt{}&lt;/code&gt; command for &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt; directly in Rmarkdown.&lt;/li&gt;
&lt;li&gt;We can evaluate and print the results of inline R code by including the letter &lt;code&gt;r&lt;/code&gt; at the beginning of an inline code chunk (delimited by backticks). This code is evaluated before the document is compiled, so the information being passed to &lt;code&gt;\texttt{}&lt;/code&gt; is the &lt;em&gt;results&lt;/em&gt; of the R code rather than the text of the R code itself.&lt;/li&gt;
&lt;li&gt;Do the same basic setup for the commit hash, commit message (in a footnote), and the compilation date. Note that the formatting of the compilation date gives you prettier results than the Rmarkdown default.&lt;/li&gt;
&lt;li&gt;Lastly, you can link the reader to the most recent public PDF by linking to your remote master branch. By linking directly to Github (or wherever else you host the remote repository), any time you push an update to remote, your PDF will automatically be up to date. This will be true of any offline PDF, any previous PDF, and any PDF generated on any branch. This is because the URL to your master branch PDF will not change even if the PDF file itself changes!&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;caveat&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Caveat&lt;/h1&gt;
&lt;p&gt;When you push to Github, it creates new hashes that differ from your local machine. As a result, you can’t use the hash in the PDF to cross-reference the same hash on Github. This is a current shortcoming in my approach, and I expect to update this post soon once I figure out a system for incorporating the remote hash in addition to the local hash.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Causal Mediation, Bayesianly</title>
      <link>/post/bayes-mediation/</link>
      <pubDate>Wed, 19 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/bayes-mediation/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;motivation-for-this-post&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivation for this post&lt;/h1&gt;
&lt;p&gt;Over this summer, I have been organizing a reading group on causal inference for students in my department. As someone who sees data analysis problems primarily through Bayesian goggles, I have been doing extra work in my head to make sense of “Bayesian causal inference.” I’m hoping to write some articles about this for political scientists, but the dissertation (rightly) has more of my attention lately.&lt;/p&gt;
&lt;p&gt;We covered causal mediation this week (&lt;a href=&#34;https://imai.fas.harvard.edu/research/files/mediationP.pdf&#34;&gt;Imai et al. 2011 &lt;em&gt;APSR&lt;/em&gt;&lt;/a&gt;), which I thought would be a good opportunity to explain where my thoughts are going about this. So this post will briefly describe a Bayesian vantage point on causal inference and show how to use Bayesian tools to implement it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posterior-predictive-draws.-i-mean-unobserved-potential-outcomes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Posterior Predictive Draws. I mean, “Unobserved Potential Outcomes”&lt;/h1&gt;
&lt;p&gt;It should be noted up front that a Bayesian take on causal inference is not at all new (I will borrow plenty of intuition from, for example, &lt;a href=&#34;https://projecteuclid.org/download/pdf_1/euclid.aos/1176344064&#34;&gt;Rubin 1978&lt;/a&gt;), but it is pretty unfamiliar to the political science/econ folks I roll with.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;
People often ask me, “How can you even have a Bayesian experiment; don’t you already have randomization?” as if the purpose of priors is to fix confounding somehow. In fairness to non-Bayesians, if this is how Bayesian analysis used priors, I would also be mistrusting of Bayes. Luckily, priors are less presumptuous than that. You get a Bayesian experiment (or any other credible research design) by specifying priors on the parameters and obtaining a posterior distribution. It is pretty unremarkable—no different than a Bayesian analysis of a non-causal design. Remember that the causal model (by which I mean, the definition of the potential outcomes) is distinct from the methods used to &lt;em&gt;estimate&lt;/em&gt; causal parameters. Bayesian analysis is positioned closer to the estimation end of things, whereas causal modeling is a series of assumptions about identifying variation in the data. In short, you fix confounding with the design, and priors are for improving the estimation.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;While the Bayesian approach may not change the research design or the causal assumptions, it does provide a different—and intuitive, I assert—interpretation of potential outcomes. Ordinarily we write potential outcomes as &lt;span class=&#34;math inline&#34;&gt;\(Y_{i}(T_{i} = t)\)&lt;/span&gt;, the outcome value for unit &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; if it received treatment value &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. Only one potential outcome per unit is ever observed, so can’t observe the &lt;em&gt;unit-level&lt;/em&gt; causal effect &lt;span class=&#34;math inline&#34;&gt;\(\tau_{i}\)&lt;/span&gt;, but we can use a causal identification analysis to lay out the assumptions required to estimate an average effect &lt;span class=&#34;math inline&#34;&gt;\(\bar{\tau}\)&lt;/span&gt; for at least some subset of units. If we knew this average effect, we would be able to state, for each observed outcome &lt;span class=&#34;math inline&#34;&gt;\(y_{i}\)&lt;/span&gt;, what the &lt;em&gt;expected value&lt;/em&gt; of that unit’s unobserved potential outcome would be if we could set &lt;span class=&#34;math inline&#34;&gt;\(T_{i}\)&lt;/span&gt; to some value &lt;span class=&#34;math inline&#34;&gt;\(t&amp;#39;\)&lt;/span&gt; other than what was observed. In this way, the unobserved potential outcome is missing data that we can predict with an estimated the model that generates (potential) outcomes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Maybe you can see where I’m going with this.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bayesian analysis begins with joint model &lt;span class=&#34;math inline&#34;&gt;\(p\left(y, \theta \right)\)&lt;/span&gt; for outcome data &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and model parameters &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;. This is equivalently expressed as &lt;span class=&#34;math inline&#34;&gt;\(p(y \mid \theta)p(\theta)\)&lt;/span&gt;, which is to say that the distribution of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; depends on the value of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; and that &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; has its own distribution. We fit the model by conditioning on the observed &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; to obtain the posterior distribution &lt;span class=&#34;math inline&#34;&gt;\(p\left(\theta \mid y \right)\)&lt;/span&gt;. It is this updated model that represents our state of information about the process that generates potential outcomes &lt;span class=&#34;math inline&#34;&gt;\(y_{i}(t)\)&lt;/span&gt;. If we wanted to make posterior inferences about what &lt;span class=&#34;math inline&#34;&gt;\(y_{i}(t)\)&lt;/span&gt; &lt;em&gt;would have been&lt;/em&gt; (in expectation) if we could arbitrarily change &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, we would simulate the unobserved potential outcomes &lt;span class=&#34;math inline&#34;&gt;\(\tilde{y}\)&lt;/span&gt; from the model.
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
  p(\tilde{y} \mid y) &amp;amp;= \int p(\tilde{y} \mid \theta) p(\theta \mid y)d\theta
\end{align}\]&lt;/span&gt;
The unobserved potential outcome is expressed as a probability distribution because we don’t know exactly what the unobserved data would be. Its distribution depends on &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, which itself is conditioned on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, and we average over our uncertainty about &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; by integrating. This gives us a distribution for the unobserved potential outcomes that is marginal of our imperfectly estimated parameters.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Okay, so?&lt;/em&gt;&lt;/strong&gt; The Bayesian view of potential outcomes is appealing because our state of ignorance about the exact potential outcomes is an explicit feature of the model, rather than a point estimate with a post-hoc standard error. Which is to say, &lt;em&gt;we don’t know&lt;/em&gt; what the treatment effect is, and so we don’t know what the potential outcomes are, but we have a range of guesses that that we can directly evaluate using their probability distribution. This approach has a certain philosophical resonance before we get anywhere near the notion of prior information. And to whatever extent researchers already view point estimates and frequentist confidence intervals on treatment effects as “ranges of plausible values” with associated posterior probabilities, they are already doing Bayesian causal inference—just without the benefit of having formally set up the whole model. With the Bayesian approach we are actually allowed to say things like “the data suggest that this treatment effect is most likely positive” or what have you.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;causal-mediation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Causal Mediation&lt;/h1&gt;
&lt;p&gt;Causal mediation analysis is concerned with a causal graph where a treatment &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; affects an outcome &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, and the effect flows at least partially through a mediator &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;. Potential outcomes are expressed as &lt;span class=&#34;math inline&#34;&gt;\(Y_{i}(T_{i}, M_{i}(T_{i}))\)&lt;/span&gt;, where the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; depends both on the treatment assignment &lt;span class=&#34;math inline&#34;&gt;\(T_{i} = t\)&lt;/span&gt; and the resulting value of the mediator &lt;span class=&#34;math inline&#34;&gt;\(M_{i}(t)\)&lt;/span&gt;, which is itself affected by the treatment. The causal effects are a decomposition of the total (average) treatment effect.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;total treatment effect&lt;/em&gt;: how much total change in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is owed to setting the value of &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;? Written as &lt;span class=&#34;math inline&#34;&gt;\(Y(1, M(1)) - Y(0, M(0))\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;causal mediation effect&lt;/em&gt;: how much of the total change in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is attributed to &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;’s effect on &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;, which also affects &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;? Or, how much change in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is owed to the fact that &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; changed, as opposed to not changing? Written as &lt;span class=&#34;math inline&#34;&gt;\(Y(t, M(1)) - Y(t, M(0))\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;direct effect&lt;/em&gt;: how much of the change in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is not flowing through &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;? In other words, how would &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; be different even if &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; had no effect on &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;? Written as &lt;span class=&#34;math inline&#34;&gt;\(Y(1, M(t)) - Y(0, M(t))\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Imai et al. present an algorithm to estimate these quantities. We need models to describe how &lt;span class=&#34;math inline&#34;&gt;\(M(T)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y(T, M(T))\)&lt;/span&gt; are generated, but the form of these models does not affect the intuition of the algorithm. It’s like this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Estimate mediator as a function of treatment and pre-treatment covariates: &lt;span class=&#34;math inline&#34;&gt;\(M_{i} = f(T_{i}, X_{i})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Estimate the outcome as a function of the treatment, the observed mediator, and pre-treatment covariates. &lt;span class=&#34;math inline&#34;&gt;\(Y_{i} = g(T_{i}, M_{i}, X_{i})\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Using &lt;span class=&#34;math inline&#34;&gt;\(f()\)&lt;/span&gt;, generate predicted values &lt;span class=&#34;math inline&#34;&gt;\(\hat{M}\)&lt;/span&gt; for all &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Using &lt;span class=&#34;math inline&#34;&gt;\(g()\)&lt;/span&gt;, predicted values &lt;span class=&#34;math inline&#34;&gt;\(\hat{Y}\)&lt;/span&gt; for all potential outcomes &lt;span class=&#34;math inline&#34;&gt;\(y(t, M(t&amp;#39;))\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Use the appropriate &lt;span class=&#34;math inline&#34;&gt;\(\hat{Y}\)&lt;/span&gt; values to calculate average total, direct, and mediation effects.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;doing-it&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Doing it&lt;/h1&gt;
&lt;p&gt;Imai et al. demonstrate their method using (in part) an experimental study by &lt;a href=&#34;https://www.jstor.org/stable/25193860?seq=1#metadata_info_tab_contents&#34;&gt;Brader, Valentino, and Suhay 2008&lt;/a&gt; on the way news stories affect immigration attitudes through specific emotional mechanisms. Let’s do the outcome where &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; represents a participant’s decision to send an anti-immigrant message to their Congressperson (&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;), which is affected by a cue in the story about a hypothetical immigrant’s ethnicity (&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;), and moderated by the emotion of anxiety (&lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;First, Imai et al. use an OLS model to predict respondent’s anxiety in response to treatment, with pre-treatment covariates &lt;span class=&#34;math inline&#34;&gt;\(X_{i}\)&lt;/span&gt; and coefficients &lt;span class=&#34;math inline&#34;&gt;\(\zeta_{1}\)&lt;/span&gt;. Parameters are subscripted &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; for the “first stage” of the estimation.
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
  M_{i} &amp;amp;= \alpha_{1} + T_{i}\beta_{1} + X_{i}\zeta{1} + \epsilon_{i}
\end{align}\]&lt;/span&gt;
They then use a probit model to estimate the outcome variable, the “second stage” (subscripted 2). This model includes the mediator with coefficient &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt;.
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
  p(Y_{i} = 1) &amp;amp;= \Phi\left(\alpha_{2} + T_{i}\beta_{2} + M_{i}\gamma + X_{i}\zeta_{2}\right)
\end{align}\]&lt;/span&gt;
You should be able to code to implement this routine in R &lt;a href=&#34;https://github.com/mikedecr/site-leavit/blob/master/static/code-blogs/R/bayes-mediation.R&#34;&gt;here&lt;/a&gt;, which calls &lt;a href=&#34;https://github.com/mikedecr/site-leavit/blob/master/static/code-blogs/stan/mediation-bvs.stan&#34;&gt;this Stan file&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In Stan, it is easy to generate posterior quantities of interest in the &lt;code&gt;generated quantities&lt;/code&gt; block of a Stan file. For example, generating posterior predictions for mediator values at &lt;span class=&#34;math inline&#34;&gt;\(T \in \{0, 1\}\)&lt;/span&gt; is as easy as…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;m0 = alpha_m + (0 * beta_m) + (X * zeta_m);
m1 = alpha_m + (1 * beta_m) + (X * zeta_m);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because &lt;code&gt;alpha_m&lt;/code&gt;, &lt;code&gt;beta_m&lt;/code&gt;, and &lt;code&gt;zeta_m&lt;/code&gt; are all uncertain parameters, what we are actually doing is generating &lt;code&gt;m0&lt;/code&gt; and &lt;code&gt;m1&lt;/code&gt; in each iteration of the sampler, thus creating a distribution of predicted mediator values. In the integral notation from above, what we’re actually doing is generating a distribution &lt;span class=&#34;math inline&#34;&gt;\(p\left(M(t)\right)\)&lt;/span&gt; by marginalizing over all of the parameters (except for the error term, which is presumably fixed in the counterfactual case).
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
  p\left(\tilde{M}(t)\right) &amp;amp;= \int p\left(\tilde{M}(t) \mid \alpha_{1}, \beta_{1}, \zeta_{1}\right) p(\alpha_1, \beta_1, \zeta_1 \mid M)d\alpha_1 d\beta_1 d\zeta_1
\end{align}\]&lt;/span&gt;
Hopefully I haven’t messed up the integral.&lt;/p&gt;
&lt;p&gt;Posterior predictions for new potential outcome observation &lt;span class=&#34;math inline&#34;&gt;\(\tilde{Y}(t, M(t&amp;#39;))\)&lt;/span&gt; would be…
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
  p\left(\tilde{Y}(t, m(t&amp;#39;))\right) &amp;amp;= \int p\left(\tilde{Y}(t, M(t&amp;#39;)) \mid \alpha_2, \beta_2, \tilde{M}(t&amp;#39;), \gamma, \zeta_2 \right) \times \\[6pt]&amp;amp;\qquad p\left(\alpha_2, \beta_2, \tilde{M}(t&amp;#39;), \gamma, \zeta_2 \mid Y\right) d\alpha_2 d\beta_2 d\tilde{M}(t) d\gamma d\zeta_2.
\end{align}\]&lt;/span&gt;
This expression is also marginalizing over the simulated mediator value &lt;span class=&#34;math inline&#34;&gt;\(M(t&amp;#39;)\)&lt;/span&gt;. Because the simulated mediator is a function of random variables, it itself is also a random variable with a probability distribution.&lt;/p&gt;
&lt;p&gt;In order to get total, direct, and mediation effects, we calculate each comparison of potential outcomes using the posterior predictive draws, and then average over each observation in the data. Here are the posterior samples for each treatment effect component.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;GGally&amp;#39;:
##   method from   
##   +.gg   ggplot2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-06-19_bayesian-causal-mediation_files/figure-html/post-hist-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And here is a comparison to the &lt;code&gt;{mediation}&lt;/code&gt; package by the Imai et al. team. We can see that, because the posterior distributions for the ACMEs are not symmetrical, there is some difference between the &lt;code&gt;{mediation}&lt;/code&gt; estimates (which come from an maximum likelihood model) and the Bayesian estimate, which is a posterior mean.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-06-19_bayesian-causal-mediation_files/figure-html/graph-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-things-to-think-about&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Other things to think about&lt;/h1&gt;
&lt;p&gt;Imai et al. propose a sensitivity analysis to measure “how much” post-treatment confounding among mediators would be enough to change your inference about causal mediation effects. While I won’t do this now, it would be possible to specify a prior on the sensitivity parameter. Such a move would let the researcher evaluate the mediation effect &lt;em&gt;marginal&lt;/em&gt; of a distribution of potential confounding, rather than merely conditional on one fixed level of confounding. This would let us make a probabilistic statement about the threat of confounding rather than a hypothetical statement. It’s of course subject to the prior, but most researchers substantively interpret their results assuming that confounding is zero, so we can think about the prior as actually relaxing an assumption of zero confounding rather than “adding a new assumption.”&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;
There are a few examples of it in political science, but the Bayesian component is used mostly for computation (MCMC) rather than for the Bayesian ideas themselves. Meanwhile Bayes-for-its-own-sake seems far more prevalent in fields like psychology, epidemiology, and biostatistics.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;
Ugh, caveating. It would be possible to represent identification assumptions as special cases of prior distributions, where the parameters of the prior can be manipulated to “relax” the assumption. For example, unconfoundedness or exclusion restrictions imply a model that contains additional covariates that each have priors that stack all probability density at exactly zero. This exercise is actually very similar to the specification of the “sensitivity parameter” in the Imai et al. mediation analysis routine.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>

---
title: "PoliSci 811: R Introduction"
description: "Some words to open this semester's R lessons"
author: "Michael DeCrescenzo"
date: '2018-02-07'
slug: "811-intro"
categories: ["R", "ps811", "Teaching"]
tags: []

# draft: true
---



Welcome to the online lessons for PS 811: Introduction to Statistical Computing for Political Science. This series of blog posts contain instructional notes for using R for political science research.

This current post contains a few introductory remarks about R, how I intend to teach R, and the structure of our coming lessons.

# Schedule:

Read this before our first R lecture.

# A little about R

R is not the only program out there for doing statistical programming, so let's begin by talking about what makes it unique. 

Compared to other popular statistical software for the social scientists (such as Stata), R stands out as a more general programming language. It isn't just a set of off-the-shelf *commands* that are punched into a program. It is a collection of functions and routines that can be used to build more complex and powerful tools for a broader set of computational uses. This has some trade-offs; it's more complicated and tougher to learn, but you can do a lot more with it. 

R is an "object-oriented" language, which essentially means that everything you interact with---datasets, variables, variable *names*, functions, etc.---is an "object" that contains either data or code to manipulate data. This makes R extremely flexible for use in statistics, as we will see throughout these lessons. 

Where other statistical software constraints you to work out of one data table, R allows you to manipulate multiple data tables. This will allow more flexibility in your work flow, but it requires you to manage more data tables. 


# R and Stata

All softwares are better suited to certain tasks than others. For example, Stata has historically been a stronger program than R for time series analysis (though time series analysis in R has seen dramatic improvement in recent years). However, R has much more flexibility than Stata to modify what your analysis is doing, allowing more explicit control over data manipulation, modeling, graphics, and workflow integration across programs. 

More specifically, Stata will make stricter assumptions about what your analysis will look like than R will. This makes it easier to perform *typical routines* using Stata than using R. On the other hand, should you ever want to extend your analysis beyond typical routines, R provides more infrastructure for making that possible, but the user has to know what they want R to do. Said slightly differently: anything you can do in Stata, you can also do in R, but things that seem simple in Stata may seem complicated in R because R will make fewer assumptions for you. 

Here is a common example that many users encounter. [Robust standard errors](https://en.wikipedia.org/wiki/Heteroscedasticity). In Stata, they are easy: `reg y x, robust`. In R, they are hard, because R will make you confront the fact that there are [many types of robust standard errors](https://www.rdocumentation.org/packages/sandwich/versions/2.4-0/topics/vcovHC). Stata picks an estimator by default and hides this decision from you. R forces you to make the decision for yourself. As a result, political science is full of robust standard errors that reflect Stata's automatic choice. 

The difference between Stata and R is kind of like the corny quote that you recognize from Spiderman: with great power comes great responsibility. R lets you *go father*, but you need to know how not to break everything. This *can be a good thing*, depending on your style of analysis. I like it, personally, but not every does, and loads of brilliant social scientists use Stata to enormous success. As you learn more about statistics, about the research you intend to do, and about the tools available to you, (and perhaps about yourself), you will have to make these software decisions for yourself---or [someone else will make the choice for you](https://twitter.com/drob/status/954056331979259904)!



# Bottom-up theory

Using R sometimes requires some familiarity with general programming concepts. This course will touch on some of these concepts as we go, but rather than hammering them to death, I will instead aim to provide resources for further learning along the way.

Some of these concepts may seem tedious at first, e.g. variables and functions. We discuss these not because you cannot be trusted to understand these concepts *in general*, but because these concepts relate to programming in not-always-obvious ways. (For example, what is the difference between a "global" and "local" variable? Or, how can a function return "random" results even if you keep the inputs the same?) The mathematical world and the programming world exhibit many similarities, and understanding how these realms relate will help you become a more skilled programmer, a stronger mathematical thinker, and a better statistical analyst.


# Pedagogical note

Because R is open-source and very flexible, there are often many different ways to accomplish the same task. Instructors, being experienced R users, see the diversity of options as an inherit benefit of R and its open-source origins, so they are often tempted to teach about the diversity. But for new R users, the diversity of R tools can be daunting and confusing. When you're learning a new language, sometimes you just want to be told what works.

We have a short time to cover as much quality R as we can, so we have to make some choices about what material to emphasize. Here is the approach we will take. (I confess that my thinking is heaviliy influenced by some blog posts by David Robinson about teaching R, including but not limited to [here](http://varianceexplained.org/r/teach-tidyverse/)).

- Rather than give you abstract exercises to demonstrate concepts in a vacuum, we'll create realistic scenarios using real data as much as we can. 
- I won't force you to slog through difficult problems using underpowered tools for the gratuitous purpose of "getting you to appreciate the finer points of the language" or whatever. Nor will we contrast old and new tools or painstakingly catalog how multiple approaches lead to the same end result. Instead, we will jump quickly into tools that I believe you will actually use in the future.
- Relatedly, this means we'll be following a philosophy of *doing as much as we can with as few powerful tools as possible*. Let's define a "powerful" tool as one that performs a complicated task with a simple interface. That's the sweet spot. 
- Hopefully this *makes R exciting to learn* because we can do real heavy lifting with it *soon*, rather than "graduating" to fun stuff after boring you with annoying stuff. 

To help us achieve these goals together, I have made the strategic decision to focus this course on the `tidyverse` suite of data manipulation packages, including `ggplot2` for graphics. There are several other "families" of data manipulation and graphics approaches, including "base R," which is where most R courses begin. Those courses then shift to other approaches after students have been beaten into submission by the inefficiency of base R. My attitude is that you are highly unlikely to use weak tools once you discover powerful tools, so I don't want to exhaust you with exercises for weak tools. Put simply, the Tidyverse is the fastest route to accomplish my goals for this course---to teach you R that is useful, realistic, simple, powerful, and fun. 


# Course structure

We will work through this course using three tools: online notes, in-class lectures, and take-home exercises.

Online notes will be the "most complete" accounting of useful R concepts, functions, and lessons. I hope that these will be a permanent resource that you can always come back to. Online notes will be easiest to read on this website, but source code for all lessons will also be available on my [Github page](https://www.github.com/mikedecr) as `.Rmd` files. I would recommend you download the source files should they ever disappear from the web in the future. We'll divide the material for this course across three lessons but using four documents (*not including* this page). You should review each lesson ***before*** its corresponding lecture day. 

- For the first week of R lecture, read this [overview of some basic R material](811/811-basics) and [this lesson on data manipulation](811/811-data). The first document covers the absolute basics---installing R, simple commands---and the second document covers data manipulation using `tidyverse` routines.
- For the second week, we will cover [graphics](811/811-graphics), with a particular focus on `ggplot2`.
- Week 3 covers [statistical analysis](811/811-analysis), including model estimation, generating model summaries and post-estimation analysis, and discussing how to incorporate your results into your written work using workflow tools. This lesson will also contain some material on advanced R tools and routines.

Lecture will be a guided walk-through of each week's material. They will cover *incomplete selections* from the online notes, so it is important to preview the notes before class. We will try to leave as much in-class time to work on take-home exercises as possible.

The take-home exercises will reinforce each week's material using an extended analysis of one dataset. These exercises are required and should be submitted on the *Thursday* following each lesson. Solutions will be made available the following day, so your work should be completed on time.

# Datasets

The dataset we will use for online notes and in-class lectures is the American National Election Study, which is a long-running academic survey of U.S. voting and public opinion. Specifically, we will work with the "[cumulative data file](http://electionstudies.org/studypages/anes_timeseries_cdf/anes_timeseries_cdf.htm)," which contains interviews from survey respondents for presidential and midterm campaign seasons since 1948. To obtain the data, make an account on [electionstudies.org](http://electionstudies.org/) and download the cumulative data file before the first in-class lesson. Make sure your download includes the codebook. You should take care of this *well in advance* of our first R lecture. If you encounter difficulties, get in touch with me *after* trying to troubleshoot your problem using the website's instructions ;-) .

Take-home exercises will use the [Database on Ideology, Money in Politics, and Elections](https://data.stanford.edu/dime#download-data), which contains information on campaign contributions for U.S. elections organized at by candidate-cycles. There are many data files in the DIME, but you should only download the "recipients" data file (and the codebook, of course).



# Seeking help, or, My role as instructor

My goal is to get you started with R, but I cannot make you an expert. You learn R mostly by doing it, and over the long run, you will learn far more from the internet than you will from me. This is as it should be---the internet is your friend. Being "good at R" means (to a certain extent) knowing what to do when you mess up, learning how to Google the error message, and learning to avoid past mistakes. To that end, when you encounter problems with R, I encourage you to start by seeking your own help online. Training yourself to find online solutions is an invaluable skill for R (and any software), so you should practice while you can. Of course, you can contact me if you find online resources to be confusing. 

Sources like Stack Overflow are great for working through R problems. So is Twitter. The most prominent R developers are active on both. 
<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Papers | Machine Learning Methods for Automated Text and Content Analysis</title>
  <meta name="description" content="Chapter 2 Papers | Machine Learning Methods for Automated Text and Content Analysis" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Papers | Machine Learning Methods for Automated Text and Content Analysis" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Papers | Machine Learning Methods for Automated Text and Content Analysis" />
  
  
  

<meta name="author" content="Michael G. DeCrescenzo" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="01-ML-stats.html"/>

<script src="_assets-gitbook/jquery-2.2.3/jquery.min.js"></script>
<link href="_assets-gitbook/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="_assets-gitbook/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="_assets-gitbook/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="_assets-gitbook/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="_assets-gitbook/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="_assets-gitbook/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="_assets-gitbook/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">ML for Text and Content</a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="01-ML-stats.html"><a href="01-ML-stats.html"><i class="fa fa-check"></i><b>1</b> Statistics from the ML Point of View</a><ul>
<li class="chapter" data-level="1.1" data-path="01-ML-stats.html"><a href="01-ML-stats.html#broad-contours"><i class="fa fa-check"></i><b>1.1</b> Broad contours</a><ul>
<li class="chapter" data-level="1.1.1" data-path="01-ML-stats.html"><a href="01-ML-stats.html#mapping-between-jargons"><i class="fa fa-check"></i><b>1.1.1</b> Mapping between jargons</a></li>
<li class="chapter" data-level="1.1.2" data-path="01-ML-stats.html"><a href="01-ML-stats.html#predictive-accuracyerror"><i class="fa fa-check"></i><b>1.1.2</b> Predictive accuracy/error</a></li>
<li class="chapter" data-level="1.1.3" data-path="01-ML-stats.html"><a href="01-ML-stats.html#overfitting"><i class="fa fa-check"></i><b>1.1.3</b> Overfitting</a></li>
<li class="chapter" data-level="1.1.4" data-path="01-ML-stats.html"><a href="01-ML-stats.html#sample-splitting"><i class="fa fa-check"></i><b>1.1.4</b> Sample splitting</a></li>
<li class="chapter" data-level="1.1.5" data-path="01-ML-stats.html"><a href="01-ML-stats.html#regularization"><i class="fa fa-check"></i><b>1.1.5</b> Regularization</a></li>
<li class="chapter" data-level="1.1.6" data-path="01-ML-stats.html"><a href="01-ML-stats.html#tuning-a-model-with-cross-validation"><i class="fa fa-check"></i><b>1.1.6</b> Tuning a model with cross-validation</a></li>
<li class="chapter" data-level="1.1.7" data-path="01-ML-stats.html"><a href="01-ML-stats.html#workflow-recap"><i class="fa fa-check"></i><b>1.1.7</b> Workflow Recap</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="01-ML-stats.html"><a href="01-ML-stats.html#broad-takeaways-for-academic-statistics"><i class="fa fa-check"></i><b>1.2</b> Broad takeaways for academic statistics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="02-papers.html"><a href="02-papers.html"><i class="fa fa-check"></i><b>2</b> Papers</a><ul>
<li class="chapter" data-level="2.1" data-path="02-papers.html"><a href="02-papers.html#shugars-the-structure-of-reasoning-measuring-justification-and-preferences-in-text"><i class="fa fa-check"></i><b>2.1</b> Shugars, “The Structure of Reasoning: Measuring Justification and Preferences in Text”</a><ul>
<li class="chapter" data-level="2.1.1" data-path="02-papers.html"><a href="02-papers.html#word-embedding"><i class="fa fa-check"></i><b>2.1.1</b> Word embedding</a></li>
<li class="chapter" data-level="2.1.2" data-path="02-papers.html"><a href="02-papers.html#network-structure"><i class="fa fa-check"></i><b>2.1.2</b> Network structure</a></li>
<li class="chapter" data-level="2.1.3" data-path="02-papers.html"><a href="02-papers.html#analysis-of-similar-networks"><i class="fa fa-check"></i><b>2.1.3</b> Analysis of similar networks</a></li>
<li class="chapter" data-level="2.1.4" data-path="02-papers.html"><a href="02-papers.html#analysis-of-dissimilar-networks"><i class="fa fa-check"></i><b>2.1.4</b> Analysis of dissimilar networks:</a></li>
<li class="chapter" data-level="2.1.5" data-path="02-papers.html"><a href="02-papers.html#original-data"><i class="fa fa-check"></i><b>2.1.5</b> Original data</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning Methods for Automated Text and Content Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="papers" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Papers</h1>
<div id="shugars-the-structure-of-reasoning-measuring-justification-and-preferences-in-text" class="section level2">
<h2><span class="header-section-number">2.1</span> Shugars, “The Structure of Reasoning: Measuring Justification and Preferences in Text”</h2>
<p>This paper tries to build theoretical and operational models of political <em>reasoning</em> that takes place before opinions are expressed.
If <span class="math inline">\(y_{i}\)</span> is a survey response for person <span class="math inline">\(i\)</span>, what is the interactive network structure among their thoughts and ideas contained in <span class="math inline">\(x_{i}\)</span>?</p>
<p>Theoretically, we invoke a network model of political ideas and justifications.
Some ideas are connected to other ideas, and that’s how conversations work.
Psych, linguistic, and philosophical takes use networks to represent memories, argumentative premises, and normative ideas like “coherence” or moral underpinnings.</p>
<p>Method has two main parts:</p>
<ol style="list-style-type: decimal">
<li>Word embeddings.
Use Google News corpus to create a “grammatical parse” or each word in grammatical structure.</li>
<li>Create a network of original datasets out of the grammatical structures of each words.
These networks are the basis of the original data analysis.</li>
</ol>
<div id="word-embedding" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Word embedding</h3>
<p>A word embedding is a word’s location in a 300-D space.
Call this a word’s “vector representation.”
<span class="math display">\[\begin{align}
  \frac{1}{T} \sum\limits_{t = 1}^{T} \sum\limits_{-c \leq j \leq c: j \neq 0}
  \log p\left(w_{t+j} \mid w_{t} \right)
\end{align}\]</span>
For a sequence of training words <span class="math inline">\(w_{1}, w_{2}, \ldots, w_{T}\)</span> and a context window <span class="math inline">\(c\)</span>.
In other words, a training model tries to predict word <span class="math inline">\(w_{t + j}\)</span> using word <span class="math inline">\(w_{t}\)</span>, and the word vectors that are selected are the vectors that best predict each word’s surrounding words.</p>
<p>This is used to define which words belong to which <em>concepts.</em> “In this paper, clusters of words are taken to refer to the same concept if all words in that cluster have cosine similarity greater than 0.5.”
Concepts serve then as nodes (I think).</p>
</div>
<div id="network-structure" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Network structure</h3>
<p>Use a “grammatical parse” to determine how nodes are connected, not just their proximity.
Grammatical connection between nodes creates edges.
All occurrences of a concept (read: word within a concept) are treated as a single node, so one node’s edges contain all grammatical connections between a concept and other concepts.</p>
</div>
<div id="analysis-of-similar-networks" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Analysis of similar networks</h3>
<p>You can construct a graph for each individual, but there is no guarantee that they contain overlapping nodes to compare structure.</p>
<p>To compare two arbitrary networks, we use “portrait divergence” (Bagrow and Bollt 2019).
Each graph (for each individual) has a “portrait” <span class="math inline">\(B\)</span>, which is an asymmetric matrix.
Entry <span class="math inline">\(B_{kl}\)</span> “captures the number of nodes <span class="math inline">\(k\)</span> which have path length <span class="math inline">\(l\)</span>”.
From Bagrow and Bollt: <span class="math inline">\(B_{kl}\)</span> is the number of nodes who have <span class="math inline">\(k\)</span> nodes at distance <span class="math inline">\(l\)</span>.
Similarity between two networks is measured as Kolmogoros-Smirnov statistic, which is the “maximum distance” between two networks.</p>
</div>
<div id="analysis-of-dissimilar-networks" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Analysis of dissimilar networks:</h3>
<p>There is a suite of network connectivity measures (average degree, clustering, giant component percent, density) and network heterogeneity measures (standard deviation of degree, entropy, assortativity).
There is a helpful Table 1 that describes these.</p>
</div>
<div id="original-data" class="section level3">
<h3><span class="header-section-number">2.1.5</span> Original data</h3>
<p>An MTurk survey of free-response answers, and a secondary YouGov survey by Dan Hopkins and Hans Noel of ideological “Turing test” responses.
The ideological Turing test asks participants to argue both sides of an issue, and see if they can do it convincingly.
Only half of participants were sincere in their participation.
Shugars interpretation is: only half are <em>argumentatively structured so as to be meaningful</em>, which we can take advantage of for analyzing the structure of reasoning.</p>
<p>MTurk data: network measures are correlated with personality traits and ideology.
That is, not just policy preferences, but the way those preferences are reasoned about!
“…combination of network statistics suggests that progressive subjects tend to form networks with a core–periphery structure—that is, networks with an interconnected core of central ideas surrounded by a periphery of loosely connected auxiliary ideas.”
And “Conservative subjects…produce more homogeneous networks in which each idea is roughly similarly connected, but further suggests these subjects tend to produce less content overall…We also see through the giant component metric that conservative subjects are more likely to produce networks with multiple, disconnected components while progressives are more like to produce connected networks, suggesting that a major difference in structure may be a tendency to ‘bridge’ between different clusters of distinct thought, with progressives more likely to tie disparate concepts together and conservatives more likely to articulate differing strains of though separately.”</p>
<p>YouGov data: network stats predict the human-coded Turing test classification, meaning they capture the quality of reasoning.
Shugars additionally asks if responses are driven by <em>content similarity</em>, or <em>individual traits</em>?
Meaning, is <span class="math inline">\(i\)</span>’s conservative response more similar to <span class="math inline">\(i\)</span>’s liberal response (individual traits drive response similarity), or more similar to <span class="math inline">\(j \neq i\)</span>’s conservative response (content of response drives argumentative similarity)?
Answer: individual is closer to themselves, suggesting that network structure captures individual level patterns in reasoning and thinking, not content-driven connections.</p>

</div>
</div>
</div>







            </section>

          </div>
        </div>
      </div>
<a href="01-ML-stats.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="_assets-gitbook/gitbook-2.6.7/js/app.min.js"></script>
<script src="_assets-gitbook/gitbook-2.6.7/js/lunr.js"></script>
<script src="_assets-gitbook/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="_assets-gitbook/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="_assets-gitbook/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="_assets-gitbook/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="_assets-gitbook/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="_assets-gitbook/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="_assets-gitbook/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["kathy-ML-primer.pdf"],
"toc": {
"collapse": "subsection"
},
"split_bib": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

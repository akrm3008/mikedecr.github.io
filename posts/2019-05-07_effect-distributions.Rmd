---
title: "The Model is Itself a Hierarchical Variable"
author: Michael DeCrescenzo
description: "A Reaction to Some Tweets"
date: '2019-05-07'
slug: model-if-variable
categories: ["Methods"]
tags: ["Causal inference", "Bayesian statistics"]
comments: no
showcomments: yes
showpagemeta: yes
draft: true
# nature:
#       beforeInit: "https://platform.twitter.com/widgets.js"
---

# Tweets

- I should do more than vague-tweet abt this.
ðŸ”¸ Treatment fx are unknown! I think techniques that tell us about the distribution of plausible fx are improvements over "robustness tests" if the latter focus on the robustness of the num. of stars vs substantive inferences about fx
- ðŸ”¸ Engaging directly w/ the parameter val as the actual qty of interest, not its sign. Maybe it's just me but I can't grok a "purely directional" hypotheses. How common are cases where an estimate of 1 gives us the same info as an effect of 1mil, or 1/1mil. They're all > 0
- ðŸ”¸ The model can be a variable in the analysis. Bayes can do this w/ prior prob of the model, & models don't need equal priors. Concepts like "goodness of fit" via marginal likelihood can be weird for causal inference though because GOF isn't a measure of causal identification


# Outline

- Intro
- If posterior distributions did not exist, we would have to invent them
- Can think of no examples where we only have a directional hypothesis

# Notes


[Original paper](https://t.co/L4AMcbbS2g?amp=1)

[Holbein sub-thread](https://twitter.com/JohnHolbein1/status/1125726900331130880)

[Holbein: direction vs. size](https://twitter.com/JohnHolbein1/status/1125727699639701505)

- This is why I care about Bayesian causal inference
- The direction is often not what we care about
  - what if it were positive but 10 million?
  - what about situations where we know that the effect has to be in some direction?
    - List experiments and the TRUE parameter
    - Voter ID and KNOWING that it isn't zero
- The "Bayesian $p$-value" is a function of the underlying thing that we care about: the causal parameter


- compliment the approach, it's reinforcing the idea that we are uncertain about the system
- The model is also variable (an uncertain parameter); so vary it
- This fits in a Bayesian framework
- The prior is flat

## The model is a itself a variable in the system

Bayes w/out Frequentist language

- data and parameters are variables (known vs unknown)
- parameters are unknown so given some prior
- the data update the prior

The model is a variable

- really, a parameter
- we don't know which is "right"
- we approximate our information with a probability distribution





Bayes factors

- Calculate the probability of the data, given the model
  - the marginal likelihood
- Weight by the prior 


The marginal likelihood

- The probability of the data, integrating over parameters

- The treatment effect is uncertain
  - Frequentism is a *point estimate*. The confidence interval is an asymptotic result from *repeated sampling*
  - Even in a one-off sample with no repetition, we the treatment effect *could be bigger* and *could be smaller*

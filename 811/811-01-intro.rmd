---
title: "PoliSci 811: Introduction (to R)"
description: "Brief introduction to this semester's R lessons. READ BEFORE CLASS."
author: "Michael DeCrescenzo"
date: '2017-11-29'
slug: 811-intro
categories: ["R", "ps811", "Teaching"]
tags: []

# draft: true
---


# Introduction

Materials for this course are written for graduate students in political science at the University of Wisconsin--Madison. Individuals from wider audiences may find some material here useful, but they should be aware that they are not the intended audience.


# R: the Why

<!-- I don't really like this as the first section -->

As a researcher, you should always be doing *automated analysis*. That is, your analysis should be controlled by code, rather than spread sheet formulas or drop-down menus. Code allows your analysis to be reproduced by your future self and by other individuals, it facilitates collaboration, and it keeps projects organized. R is not the only platform available for doing this kind of work, but it is a particularly great one. 

Compared to other popular statistical software for the social scientists (such as Stata), R stands out as a more general *programming language*. Said another way, R is more than a set of *commands* that are punched into a program; it is a collection of functions and routines that can be used to build more and more complex and powerful functions and routines.^[Stata does have the `Mata` syntax, which can be used to create custom Stata routines, but it stands as a distinct syntax from vanilla Stata.] This has some trade-offs---it requires some more up-front investment by the user. That being said, these investments pay off in many ways: using R in the future, learning other programming languages, and even learning more advanced mathematics. 

R is an "object-oriented" language, which makes it extremely flexible for use in statistics. It also helps you learn other similar languages that have advantages over R for certain uses---Python for scraping and GIS, C++/Stan for Bayesian analysis, and so on. 

More generally, some softwares are suited to some tasks better than others. For example, time series analysis is Stata's bread and butter much more than it is R's (though time series analysis using R has been greatly improving lately). However, R has much more flexibility than Stata to modify what your analysis is doing, allowing finer control over data manipulation, modeling, graphics, and workflow integration. In general, it is fair to say that Stata makes many more decisions for the user about what it thinks the user wants to do. R does not make as many assumptions. This has its benefits and drawbacks. Many "typical" routines are easier in Stata than in R. R, on the other hand, allows for much greater complexity beyond the typical routine, but it requires the user to know more about what the typical routine *actually is*.

Put a different way: just about anything that you can do in Stata, you can also do in R, but some things that are simple in Stata are a little weird in R. This is because R has a tendency to reveal something about "typical" routines: just because they are typical doesn't mean they are *simple* or free of complex assumptions. Those assumptions aren't *gone* in Stata; they are only hidden. For example, estimating a linear regression in Stata using robust (that is, [heteroskedasticity](https://en.wikipedia.org/wiki/Heteroscedasticity)-consistent) standard errors is as simple as `reg y x, robust`. If you try to do robust standard errors in R, however, you come face to face with something that Stata does not like to tell you: there are many, many, *many* types of [standard errors for heteroskedasticity](https://www.rdocumentation.org/packages/sandwich/versions/2.4-0/topics/vcovHC), and the analyst must choose which type they want. Stata makes this choice for the user, and as a result, political science is full of "robust" standard errors that many researchers may not understand.

In summary, R sometimes puts more demands on the user's knowledge of statistics and programming. I find this to be helpful and a good thing, for a few reasons. I don't want to take too many things about my analysis for granted. I want to be reassured that I know what I'm doing, and I like to know the details. I also like to be able to use fancy-shmancy programming tricks to interact with my data in certain ways. But not every user will need this flexibility, and many smart social scientists use Stata to great success. As you learn more about statistics, the research you intend to do, and the softwares available to you, you will have to make these software decisions for yourself (or someone else will make the choice for you!).



# Bottom-up theory

Because R is a more flexible and extensible programming language than Stata is, it sometimes requires some deeper knowledge of programming concepts. This course will touch on some of these concepts as we go, but rather than hammering them to death, I will instead aim to provide resources for further learning along the way.

Some of these concepts, such as variables and functions, may seem tedious at first. We will cover these not because you cannot be trusted to understand these concepts *in general*, but because these concepts relate to programming in not-always-obvious ways. (For example, what is the difference between a global and local variable? Or, how can a function return different outputs even if you keep the inputs the same?) The mathematical world and the programming world exhibit many similarities, and understanding how these realms relate will help you become a more skilled programmer, a better mathematical thinker, and (hopefully) a better researcher.

Having said that, the intent is not to overburden new R users with too much theory. The aim is to provide helpful exposition to build a foundation with R, providing enough structure for users with different levels of R ambition to continue their own learning in the future.


# R Pedagogy

As just mentioned, R is a flexible tool for doing statistical computing. More than that, it has a *diversity of methods* that users can use to accomplish similar tasks. That is, there are many ways to do the same thing. This diversity has a few implications.

- *For intermediate and advanced R users, this diversity is a real benefit.* Users who are already comfortable with R basics will find, when they have a goal in mind, there are many routes to that goal. Their familiarity with R allows them to understand the differences between these routes (the benefits and drawbacks), so they can make a more informed decision about the best tools to use.
- *For new R users, this diversity can be daunting and confusing.* When you encounter a new language, sometimes you just want to be told what to do. R does not always deliver on this front. Because there are so many routines available, accomplishing simpler tasks (and seeking help about those tasks) is sometimes overwhelming. Online forums such as Stack Overflow provide users with multiple solutions that each seem to rely on a foundation of knowledge that the newcomer may not yet possess.

What do we do about this? How should we learn R in this course? What kind of concepts, tools, routines, and practices should we cover, given that we have limited time? In order to help you understand the goals for this course, I want to explain my goals as a teacher and how I hope to reach them. I confess to having my thinking heaviliy influenced by some blog posts by David Robinson about teaching R (including but not limited to [here](http://varianceexplained.org/r/teach-tidyverse/)).

1. *Teach what will be useful in the future.* This sounds almost too obvious to include, but you may be surprised to find that many teaching approaches implicitly do not believe in this goal. Some approaches start with the "basics" and then become "more complex" as they introduce more tools. What that sometimes means is, the instructor begins by asking the student to solve difficult problems with the weakest, most basic tools the language has to offer---and then only after the student spends too much time and energy working through the problem under unrealistic constraints, the teacher reveals the more powerful tool that solves the same problem with much less headache. The teacher then says, "see, isn't this way so much easier?" And indeed, the teacher isn't incorrect, but the teacher did spend a lot of time making things more painful (and probably more complicated) than was necessary. Moreover, this approach can alienate to students who want to discover the *value* of a programming language rather than waste their time on painstaking and unrealistic exercises. Given that we have just a few days to cover R in class together, I'm choosing to spend more time showing you *what works* rather than *how it works*. 
2. *Create realistic scenarios.* Many programming lessons explain how to accomplish a task without really explaining why you would want to. Similarly, the lesson may describe many routines without explaining how they fit together to solve a realistic problem. My goal is to structure lectures and take-home exercises around real data with real analytical tasks, rather than doing cute, nonsensical exercises with unrelated (and in many cases, non-political) datasets.
3. *Simplify the problem*. Sometimes, instructors demonstrate a variety of ways to accomplish the same basic task. Although this is intended to celebrate the diversity of a language, this creates a lot of mental clutter for new users. Newcomers want a path to follow, not a complicated web of options that contains little strategic guidance. I can provide resources for tools that we do not discuss in class.
4. *Do as much as we can with as few powerful tools as possible.* Let's define a "useful" tool as one that performs a complicated task with a simple interface. That's the sweet spot. There's where we want to focus.
5. These points are in service of *making R fun and rewarding.* Because R is a more technically flexible programming language than some alternatives (Stata, SPSS, SAS), many introductions to R focus on "eating your vegetables" about how the language works instead of showing what it can do. I can never design a short course to make you an expert in R, but I can design a short course that leads you to create some awesome stuff.

To help us achieve these goals together, I have made the tactical decision to focus this course on the `tidyverse` (data manipulation packages) including `ggplot2` (for graphics). There are several other "families" of data manipulation and graphics approaches, including "base R," which is where most R courses begin. Those courses then "graduate" to other approaches after students have been beaten into submission by the inefficiency of base R. My attitude is that you are highly unlikely to use base R once you discover other tools because base R is clearly inferior, so I don't want to waste your time on it. Put simply, the tidyverse accomplishes the goals I want to focus on for the course---to teach you R that is useful, realistic, simple, powerful, and fun. 


# How the course will be structured

We will work through this course using three tools: online notes, in-class lectures, and take-home exercises.

Online notes will be the "most complete" accounting of useful R concepts, functions, and lessons. I hope that these will be a permanent resource that you can always come back to. Online notes will be easiest to read on this website, but source code for all analysis will also be available on my [Github page](https://www.github.com/mikedecr). I'd encourage you to download the source code for each lesson or clone them using Git. (I'd also encourage you to learn Git, but that is a diatribe for another day.) We'll divide the material for this course across four documents (*not including* this page).

- [First is an overview of some basic R content.](ps-811-day0-basics) This covers some introductory guidance for installing R and running simple commands. ***Review this page on your own before the first in-class R lesson.*** 
- [Day 1 covers data manipulation,](ps-811/ps-811-data) focusing specifically on useful tools in the suite of R packages commonly known as the `tidyverse`.
- [Day 2 covers graphics,](ps-811/ps-811-graphics) with a particular focus on `ggplot2`.
- [Day 3 covers statistical analysis,](ps-811/ps-811-analysis) including estimating models, generating model output, and incorporating statistical results into a social science workflow.

In-class lectures will be guided and motivated walkthroughs of code examples. We will use extended and highly motivated examples, which is to say, let's work through one dataset from lots of different angles so that we can focus as much as we can on doing cool stuff with R rather than wasting mental energy bouncing through different datasets. The dataset we will use is the American National Election Study, which is a long-running academic survey of U.S. voting and public opinion. Specifically, we will work with the "[cumulative data file](http://electionstudies.org/studypages/anes_timeseries_cdf/anes_timeseries_cdf.htm)," which contains interviews from survey respondents for presidential and midterm campaign seasons since 1948. Make an account on [electionstudies.org](http://electionstudies.org/) and download the cumulative data file before the first in-class lesson. Make sure the download includes the codebook. 

Take-home exercises will also be based on extended examples, reinforcing each material using one dataset. These exercises are recommended but not mandatory. Although there is no formal collection of your work, I will release "solutions" and am happy to review your code and work through any issues with you. Take-home exercises will use the [Database on Ideology, Money in Politics, and Elections](https://data.stanford.edu/dime#download-data), which contains information on campaign contributions for U.S. elections organized at by candidate-cycles. There are many data files in the DIME, but you should only download the data file called `dime_recipients_all_1979_2014.csv.gz`. Obviously you should also download the codebook.



# My role as instructor

My goal is to get you started with R, but as I've said already, I cannot make you an expert. You learn R mostly by doing it, and over the long run, you will learn far more from the internet than you will from me. This is as it should be---the internet is your friend. Being "good at R" means (to a certain extent) knowing what to do when you mess up, learning how best to Google the error message, and learning to avoid past mistakes. (Even the error messages begin to make sense over time.)

Sources like Stack Overflow are great for working through R problems. I'd also encourage you to follow influential R users and innovators on Twitter. (Feel free to dig through [my list of follows](https://twitter.com/mikedecr/following) for accounts.)
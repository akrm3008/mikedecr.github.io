<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Causal Inference 2: Predictive Modeling</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.1/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: middle, center






.pull-left[
# **PS 811: Statistical Computing**

&lt;br&gt;
Michael DeCrescenzo
&lt;br&gt;
University of Wisconsin–Madison

]

.pull-right[
&lt;img src="11_predictive-modeling_files/figure-html/title-graphic-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]

## Causal and Predictive Modeling 2/2: &lt;br&gt; Predictive Modeling

May 1, 2020

---

class: middle


.pull-left[

### The Interpretability–Flexibility Trade-Off

When is it important for a method to be "interpretable?"

When is it important for a method to be "flexible?"

]

.pull-right[

&lt;img src="esl-fig.png" width="100%" style="display: block; margin: auto;" /&gt;

James, Witten, Hastie, Tibshirani (2015) &lt;br&gt; "An Introduction to Statistical Learning"

]


---


# Today's Plan

--

.pull-left[
### Limits of Regression

- Prediction: functional form
- Causal inference: identification assumptions
- What **are** regression coefficients anyway? ("Aronow-Samii critique")

]

--

.pull-right[

### "Machine Learning"

- Similar tools, different philosophy
- Objectives of "predictive modeling"
- What makes a good model
- R code coming soon

]



---

class: middle, center, inverse

# Regression Woes


---

## Regression for Prediction

.left-code[

Weighted avg:
`\begin{align}
  \bar{x}^{*} = \frac{1}{n} \sum\limits_{i = 1}^{n} w_{i} x_{i}
\end{align}`

Linear regression on `\(K\)` variables:
`\begin{align}
  \hat{y}_{i} = \sum\limits_{k = 1}^{K} \beta_{k} x_{k[i]}
\end{align}`

My responsibility to specify `\(X\)`

What even is a "true" model?

]


.right-plot[

&lt;img src="morpheus.jpg" width="80%" style="display: block; margin: auto;" /&gt;
]


???

It works pretty well in many circumstances, but some fragile assumptions

Where are the "lines?"

Do "lines" best represent what I need to get a good prediction?

Later: are the lines themselves all that important to understand?



---

class: middle



&lt;img src="11_predictive-modeling_files/figure-html/unnamed-chunk-3-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

class: middle






&lt;img src="11_predictive-modeling_files/figure-html/unnamed-chunk-5-1.png" width="90%" style="display: block; margin: auto;" /&gt;


---

## Regression for Causal Inference







.pull-left[

&lt;img src="11_predictive-modeling_files/figure-html/plot-confound-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]


.pull-right[
Causal effect `\(Z \rightarrow Y\)` is **nonparametrically identified** conditioning on `\(X\)`

Must model `\(X \rightarrow Z\)` to isolate/subtract the variation `\(Z\)` that comes from `\(X\)`

**No guarantee** that `\(X \rightarrow Z\)` well represented by linear regression

"Clear interpretation" unnecessary to predict `\(Z \mid X\)`

Interactions/heterogeneity in `\(Z \rightarrow Y\)`

]


---

## Regression Coefficients aren't Causal Effects

.pull-left[
Imagine `\(\tau_{i}\)`, individual treatment effect of `\(Z_{i}\)` for unit `\(i\)`. ATE is `\(\mathrm{E}[\tau_{i}]\)`

Imagine the perfect model...

- `\(Y_{i} = \alpha + \beta Z_{i} + X_{i}\gamma + \epsilon_{i}\)`
- **Selection on observables:** controlling for `\(X\)` is sufficient to identify `\(Z \rightarrow Y\)`
- `\(\epsilon\)` independent and constant variance

Implies a "treatment model."
`\begin{align}
  \bar{Z}_i &amp;= \mathrm{E}\left[ Z_i \mid X_i \right]
\end{align}`

]

--

.pull-right[

We don't perfectly predict treatment.
`\begin{align}
  w_{i} &amp;= \left(Z_i - \bar{Z}_i\right)^2 \\
  \mathrm{E}[w_{i} \mid X_{i}] &amp;= \mathrm{Var}[Z_{i} \mid X_{i}]
\end{align}`

Regression coefficient **is not equal** to ATE
`\begin{align}
  \hat{\beta} &amp;\xrightarrow{p} \frac{\mathrm{E}[w_{i} \tau_{i}]}{\mathrm{E}[w_{i}]}
\end{align}`

Coefficient is a **weighted average** of **treatment effect** and **variance in treatment assignment**. 

]




---

## Internal/external validity and the **"effective sample"**

.pull-left[

Coefficient is (asymptotically) the ATE iff `\(w_{i}\)` independent of `\(\tau_{i}\)`

- No heterogeneity in `\(\tau_{i}\)` or heterogeneity in `\(w_{i}\)` (lol)
- Random assignment

&gt; _"There is **no general external validity basis** for preferring multiple regression on representative samples over quasi-experimental or experimental methods."_

]


--

.pull-right[

&lt;img src="chappelle.gif" width="80%" style="display: block; margin: auto;" /&gt;

]





---

## Internal/external validity and the **"effective sample"**

.pull-left[

Coefficient is (asymptotically) the ATE iff `\(w_{i}\)` independent of `\(\tau_{i}\)`

- No heterogeneity in `\(\tau_{i}\)` or heterogeneity in `\(w_{i}\)` (lol)
- Random assignment

&gt; _"There is **no general external validity basis** for preferring multiple regression on representative samples over quasi-experimental or experimental methods."_


]


.pull-right[

What can we do?

- Predict treatment propensity: `\(p(Z_{i} \mid X_{i})\)`. Compare treatments using inverse propensity weighting (IPW).
- Predict `\(Y_{i}(Z, X_{i})\)` and `\(Y_{i}(Z', X_{i})\)` for all units in the population, and compare directly.

**Even in CI world, we need good predictions more than "interpretable" regression function**



]






---

&lt;img src="11_predictive-modeling_files/figure-html/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;" /&gt;




---

class: middle, center, inverse

# What we call "Machine Learning"

---

## It's all machine learning

.pull-left[

**Every estimation method is optimizing an objective function**

- OLS: minimize residual squared error w.r.t. fixed parameters
- MLE: maximize (log) likelihood of data w.r.t. fixed parameters
- Many iterative/cross-validated models: minimize **out-of-sample mean-square error** using variety of methods

Regression is **one method of many** methods to predict `\(\mathrm{E}[Y \mid X]\)`
]

--

.pull-right[

Revising "Interpretability"

- Understanding **how model works** vs. understanding **coefficients**
- Confounding: "causal" effects may not be identified
- Collider bias: "associations" may be all topsy-turvy
- How does model work? Useful.
- What is X's confounded/collided association to `\(Y\)`? ...Is this useful?
]



---


## Smoothing Splines

.left-code[

Take a variable `\(x\)` and construct `\(J\)` many "basis functions" `\(b_{j}(x)\)`

Every `\(b_{j}(x)\)` gets a weight `\(\delta_{j}\)`

Sum all basis functions and weights:

`\begin{align}
  \hat{Y}_{i} &amp;= \alpha + \sum\limits_{j} \delta_{j}b_{j}\left(x_{i}\right)
\end{align}`

Many ways to **penalize** overly wiggly smooths!

]

.right-plot[

&lt;img src="pygam_basis.png" width="80%" style="display: block; margin: auto;" /&gt;

[GAMS in R](https://noamross.github.io/gams-in-r-course/): free course by Noam Ross

]



---

class: middle

### Tree/Forest Methods

.pull-left[
&lt;img src="tree-split.png" width="80%" style="display: block; margin: auto;" /&gt;

Cut the covariate space ("recursive splitting")
]


.pull-right[
&lt;img src="tree-tree.png" width="80%" style="display: block; margin: auto;" /&gt;

Each obs falls in one "cell" (leaf) 
]



---

class: middle

### Tree/Forest Methods

.pull-left[
&lt;img src="tree-response.png" width="80%" style="display: block; margin: auto;" /&gt;

Estimate response in each leaf
]


.pull-right[
&lt;img src="tree-ohio.jpg" width="80%" style="display: block; margin: auto;" /&gt;

Forests/BART: predictions avg. over trees
]




---

## ML problems and workflow

.pull-left[

What problems do I have?

- I want to estimate the "response surface" `\(\mathrm{E}[Y \mid X]\)`
- I don't know if response surface contains interactions, nonlinearities
- I don't know which covariates are important to include (too many `\(X\)`)

ML methods explore these choices for **optimal prediction**

]

--

.pull-right[
ML workflow: sample splitting

- What is a model? **Describe new data**
- "Train" (fit) model in sample A
- "Test" model in sample B 
- Reward models with lower MSE
- Overfitting leads to **greater** MSE

**Out of sample prediction is smart even with classical regression.**

]


---

## Regularization to prevent overfitting

.pull-left[
In OLS, MLE, etc., every model is overfit

- Predictions are made **in-sample**

- Model of the data isn't validated against data it hasn't seen

]

--

.pull-right[
Regularization or "penalized estimation"

- Example: hierarchical models.
`\begin{align}
  y_{i} &amp;= \alpha_{j[i]} + X_{i}\beta + \epsilon \\ 
  \alpha_{j} &amp;\sim \mathrm{Normal}(\bar{\alpha}, \sigma_{\alpha})
\end{align}`
- Bias/variance trade-off: less data in group `\(j\)`, more shrinkage toward `\(\bar{\alpha}\)`


]



---

## **Tuning** to prevent overfitting

.pull-left[
Models tend to overfit

- Regularization, stratification, etc., controlled by **hyperparameters**
- Researcher must set hyperparameters
- How?

]

--


.pull-right[
**Cross-validation**

- Sample A (train): fit model repeatedly w/ different hyperparameters
- Sample B (test): see which hyperparams have best out-of-sample MSE
- Sample C (predict): Generate predictions from best model
- **Bagging** (bootstrapped aggregation): repeat so that you mix up your A/B/C data
]


---

## Machine Learning is more **workflow** than **modeling**

.pull-left[
Workflow principles:

- All models tend toward overfitting

- Regularize against complexity using in-model structures (priors, penalized estimation)

- Cross-validation to tune model structures that can't adapt to data
]


.pull-right[
How modeling differs

- Classic regression workflow: pick a model and estimate (read: overfit)

- Predictive modeling/ML: test (and avg. across) different modeling assumptions

- Different models experiment w/ different model setups, but the workflow points

]





---

class: middle

## Recap

.pull-left[
### Classical Regression

One of many types of predictive models

Predictions are _sometimes_ serviceable

Present real problems for causal inference (functional form, effective sample)

Interpretability vs. accuracy trade-off: false choice?

]


.pull-right[
### "Machine Learning"

Superset of predictive models, includes regression

"Learner" (model) estimates the "target" ( `\(y\)` ) from "features" ( `\(x\)` )

Flexible and accurate, but wicked oracles that must be constrained with regularization and validation

]


---

class: middle, center, inverse

# Thank you

### for enduring _tons_ of new material that your professors aren't experts with

### during a hellish time on this planet.

## THINK ABOUT HOW MUCH YOU'VE LEARNED SINCE DAY ONE.










    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
